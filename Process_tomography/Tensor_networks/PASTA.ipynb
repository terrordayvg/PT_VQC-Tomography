{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QPT consisting from the \tarXiv:2006.02424 article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run circuit MPO:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=499|\"Qubit,Site,n=1\")', (dim=2|id=499|\"Qubit,Site,n=1\"), (dim=4|id=176|\"Link,n=1\"))\n",
       "[2] ((dim=4|id=176|\"Link,n=1\"), (dim=2|id=448|\"Qubit,Site,n=2\")', (dim=2|id=448|\"Qubit,Site,n=2\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1:---------------------------------------------------------------------------This is U0:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=499|\"Qubit,Site,n=1\")', (dim=4|id=488|\"Link,l=1\"), (dim=2|id=499|\"Qubit,Site,n=1\"))\n",
       "[2] ((dim=2|id=448|\"Qubit,Site,n=2\")', (dim=4|id=488|\"Link,l=1\"), (dim=2|id=448|\"Qubit,Site,n=2\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2---------------------------------------------Part 3---------------------------------------------1     ⟨logP⟩ = 3.4220  (2.7769)  elapsed = 0.158s\n",
      "2     ⟨logP⟩ = 3.2928  (2.8446)  elapsed = 0.148s\n",
      "3     ⟨logP⟩ = 3.1704  (2.8470)  elapsed = 0.137s\n",
      "4     ⟨logP⟩ = 3.0759  (2.8477)  elapsed = 0.138s\n",
      "5     ⟨logP⟩ = 2.9947  (2.8010)  elapsed = 0.148s\n",
      "6     ⟨logP⟩ = 2.9101  (2.7600)  elapsed = 0.141s\n",
      "7     ⟨logP⟩ = 2.8450  (2.7550)  elapsed = 0.145s\n",
      "8     ⟨logP⟩ = 2.7817  (2.8069)  elapsed = 0.149s\n",
      "9     ⟨logP⟩ = 2.7317  (2.7818)  elapsed = 0.147s\n",
      "10    ⟨logP⟩ = 2.6942  (2.7904)  elapsed = 0.133s\n",
      "11    ⟨logP⟩ = 2.6662  (2.8219)  elapsed = 0.148s\n",
      "12    ⟨logP⟩ = 2.6487  (2.8937)  elapsed = 0.151s\n",
      "13    ⟨logP⟩ = 2.6276  (2.9672)  elapsed = 0.141s\n",
      "14    ⟨logP⟩ = 2.6091  (2.8480)  elapsed = 0.145s\n",
      "15    ⟨logP⟩ = 2.6015  (2.7915)  elapsed = 0.146s\n",
      "16    ⟨logP⟩ = 2.5879  (2.7515)  elapsed = 0.152s\n",
      "17    ⟨logP⟩ = 2.5832  (2.7105)  elapsed = 0.138s\n",
      "18    ⟨logP⟩ = 2.5674  (2.6804)  elapsed = 0.141s\n",
      "19    ⟨logP⟩ = 2.5661  (2.6870)  elapsed = 0.151s\n",
      "20    ⟨logP⟩ = 2.5541  (2.6058)  elapsed = 0.159s\n",
      "21    ⟨logP⟩ = 2.5466  (2.5347)  elapsed = 0.134s\n",
      "22    ⟨logP⟩ = 2.5456  (2.4827)  elapsed = 0.141s\n",
      "23    ⟨logP⟩ = 2.5403  (2.4417)  elapsed = 0.148s\n",
      "24    ⟨logP⟩ = 2.5221  (2.4091)  elapsed = 0.142s\n",
      "25    ⟨logP⟩ = 2.5257  (2.3841)  elapsed = 0.142s\n",
      "26    ⟨logP⟩ = 2.5191  (2.3640)  elapsed = 0.144s\n",
      "27    ⟨logP⟩ = 2.4937  (2.3494)  elapsed = 0.140s\n",
      "28    ⟨logP⟩ = 2.4964  (2.3391)  elapsed = 0.144s\n",
      "29    ⟨logP⟩ = 2.4784  (2.3374)  elapsed = 0.134s\n",
      "30    ⟨logP⟩ = 2.4729  (2.3381)  elapsed = 0.139s\n",
      "31    ⟨logP⟩ = 2.4591  (2.3421)  elapsed = 0.148s\n",
      "32    ⟨logP⟩ = 2.4575  (2.3505)  elapsed = 0.135s\n",
      "33    ⟨logP⟩ = 2.4446  (2.3647)  elapsed = 0.143s\n",
      "34    ⟨logP⟩ = 2.4434  (2.3842)  elapsed = 0.152s\n",
      "35    ⟨logP⟩ = 2.4303  (2.3947)  elapsed = 0.144s\n",
      "36    ⟨logP⟩ = 2.4213  (2.3718)  elapsed = 0.144s\n",
      "37    ⟨logP⟩ = 2.4153  (2.3553)  elapsed = 0.147s\n",
      "38    ⟨logP⟩ = 2.4029  (2.3473)  elapsed = 0.144s\n",
      "39    ⟨logP⟩ = 2.4015  (2.3494)  elapsed = 0.149s\n",
      "40    ⟨logP⟩ = 2.3886  (2.3518)  elapsed = 0.148s\n",
      "41    ⟨logP⟩ = 2.3769  (2.3390)  elapsed = 0.138s\n",
      "42    ⟨logP⟩ = 2.3818  (2.3343)  elapsed = 0.146s\n",
      "43    ⟨logP⟩ = 2.3683  (2.3263)  elapsed = 0.156s\n",
      "44    ⟨logP⟩ = 2.3648  (2.3195)  elapsed = 0.153s\n",
      "45    ⟨logP⟩ = 2.3504  (2.3202)  elapsed = 0.156s\n",
      "46    ⟨logP⟩ = 2.3464  (2.3238)  elapsed = 0.153s\n",
      "47    ⟨logP⟩ = 2.3487  (2.3309)  elapsed = 0.139s\n",
      "48    ⟨logP⟩ = 2.3269  (2.3372)  elapsed = 0.150s\n",
      "49    ⟨logP⟩ = 2.3224  (2.3402)  elapsed = 0.144s\n",
      "50    ⟨logP⟩ = 2.3351  (2.3377)  elapsed = 0.139s\n",
      "51    ⟨logP⟩ = 2.3113  (2.3344)  elapsed = 0.144s\n",
      "52    ⟨logP⟩ = 2.3182  (2.3273)  elapsed = 0.147s\n",
      "53    ⟨logP⟩ = 2.3242  (2.3177)  elapsed = 0.138s\n",
      "54    ⟨logP⟩ = 2.3147  (2.3055)  elapsed = 0.145s\n",
      "55    ⟨logP⟩ = 2.3232  (2.2960)  elapsed = 0.138s\n",
      "56    ⟨logP⟩ = 2.3166  (2.2843)  elapsed = 0.142s\n",
      "57    ⟨logP⟩ = 2.3198  (2.2738)  elapsed = 0.149s\n",
      "58    ⟨logP⟩ = 2.3100  (2.2647)  elapsed = 0.134s\n",
      "59    ⟨logP⟩ = 2.3068  (2.2550)  elapsed = 0.137s\n",
      "60    ⟨logP⟩ = 2.3133  (2.2439)  elapsed = 0.141s\n",
      "61    ⟨logP⟩ = 2.3040  (2.2349)  elapsed = 0.147s\n",
      "62    ⟨logP⟩ = 2.2979  (2.2264)  elapsed = 0.158s\n",
      "63    ⟨logP⟩ = 2.3100  (2.2205)  elapsed = 0.135s\n",
      "64    ⟨logP⟩ = 2.3021  (2.2162)  elapsed = 0.142s\n",
      "65    ⟨logP⟩ = 2.3137  (2.2127)  elapsed = 0.158s\n",
      "66    ⟨logP⟩ = 2.3042  (2.2070)  elapsed = 0.152s\n",
      "67    ⟨logP⟩ = 2.2978  (2.2043)  elapsed = 0.145s\n",
      "68    ⟨logP⟩ = 2.3055  (2.2030)  elapsed = 0.149s\n",
      "69    ⟨logP⟩ = 2.2911  (2.2005)  elapsed = 0.142s\n",
      "70    ⟨logP⟩ = 2.3016  (2.1968)  elapsed = 0.143s\n",
      "71    ⟨logP⟩ = 2.2946  (2.1931)  elapsed = 0.151s\n",
      "72    ⟨logP⟩ = 2.2983  (2.1954)  elapsed = 0.140s\n",
      "73    ⟨logP⟩ = 2.3092  (2.2021)  elapsed = 0.147s\n",
      "74    ⟨logP⟩ = 2.3081  (2.2079)  elapsed = 0.143s\n",
      "75    ⟨logP⟩ = 2.3019  (2.2145)  elapsed = 0.137s\n",
      "76    ⟨logP⟩ = 2.3043  (2.2197)  elapsed = 0.145s\n",
      "77    ⟨logP⟩ = 2.3132  (2.2242)  elapsed = 0.138s\n",
      "78    ⟨logP⟩ = 2.2946  (2.2301)  elapsed = 0.143s\n",
      "79    ⟨logP⟩ = 2.2977  (2.2316)  elapsed = 0.150s\n",
      "80    ⟨logP⟩ = 2.3032  (2.2306)  elapsed = 0.152s\n",
      "81    ⟨logP⟩ = 2.3007  (2.2290)  elapsed = 0.132s\n",
      "82    ⟨logP⟩ = 2.3141  (2.2290)  elapsed = 0.143s\n",
      "83    ⟨logP⟩ = 2.3045  (2.2242)  elapsed = 0.142s\n",
      "84    ⟨logP⟩ = 2.3036  (2.2204)  elapsed = 0.141s\n",
      "85    ⟨logP⟩ = 2.3000  (2.2156)  elapsed = 0.149s\n",
      "86    ⟨logP⟩ = 2.2889  (2.2010)  elapsed = 0.139s\n",
      "87    ⟨logP⟩ = 2.3000  (2.1883)  elapsed = 0.144s\n",
      "88    ⟨logP⟩ = 2.2932  (2.1779)  elapsed = 0.143s\n",
      "89    ⟨logP⟩ = 2.2936  (2.1693)  elapsed = 0.154s\n",
      "90    ⟨logP⟩ = 2.3008  (2.1642)  elapsed = 0.147s\n",
      "91    ⟨logP⟩ = 2.2992  (2.1633)  elapsed = 0.149s\n",
      "92    ⟨logP⟩ = 2.3000  (2.1629)  elapsed = 0.135s\n",
      "93    ⟨logP⟩ = 2.2960  (2.1644)  elapsed = 0.141s\n",
      "94    ⟨logP⟩ = 2.2956  (2.1639)  elapsed = 0.151s\n",
      "95    ⟨logP⟩ = 2.2886  (2.1640)  elapsed = 0.143s\n",
      "96    ⟨logP⟩ = 2.2933  (2.1632)  elapsed = 0.138s\n",
      "97    ⟨logP⟩ = 2.2845  (2.1608)  elapsed = 0.138s\n",
      "98    ⟨logP⟩ = 2.2901  (2.1587)  elapsed = 0.141s\n",
      "99    ⟨logP⟩ = 2.2934  (2.1569)  elapsed = 0.135s\n",
      "100   ⟨logP⟩ = 2.2844  (2.1533)  elapsed = 0.141s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=499|\"Qubit,Site,n=1\")', (dim=4|id=488|\"Link,l=1\"), (dim=2|id=499|\"Qubit,Site,n=1\"))\n",
       "[2] ((dim=2|id=448|\"Qubit,Site,n=2\")', (dim=4|id=488|\"Link,l=1\"), (dim=2|id=448|\"Qubit,Site,n=2\"))\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PastaQ\n",
    "using Random\n",
    "using ITensors\n",
    "using Observers\n",
    "using Optimisers: Optimisers\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "using SCS\n",
    "using Convex\n",
    "\n",
    "N = 2\n",
    "nshots = 1\n",
    "gates = randomcircuit(N; depth=10)\n",
    "Λ1 = runcircuit(gates; process=true)\n",
    "\n",
    "print(\"Run circuit MPO:\")\n",
    "display(Λ1)\n",
    "\n",
    "#For training data\n",
    "preps = randompreparations(N,4) #random initialization of states\n",
    "bases = randombases(N,4)        #random basis of measurements\n",
    "data = getsamples(Λ1, preps, bases,100) #Get samples for these datapoints accordingly to the preparation and basis\n",
    "\n",
    "#For testing data\n",
    "preps = randompreparations(N,4)\n",
    "bases = randombases(N,4)\n",
    "target = getsamples(Λ1, preps, bases, 2)\n",
    "\n",
    "print(\"Part 1:----------------------------------\")\n",
    "#display(data)\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "χ = maxlinkdim(Λ1) #\n",
    "U0 = randomprocess(Λ1,mixed=false; χ=χ) #definition of the variational circuit\n",
    "print(\"This is U0:\")\n",
    "display(U0)\n",
    "print(\"Part 2---------------------------------------------\")\n",
    "\n",
    "#F(bu::LPDO; kwargs...) = fidelity(bu, Λ; process=true)\n",
    "#obs = Observer([\"F\" => F])\n",
    "\n",
    "print(\"Part 3---------------------------------------------\")\n",
    "\n",
    "N = size(data, 2) # Number of qubits\n",
    "\n",
    "opt = Optimisers.ADAM() #optimizer\n",
    "#opt=Optimisers.Descent(0.01)\n",
    "\n",
    "# Run quantum state tomography\n",
    "Λ = tomography(data, U0; optimizer = opt, test_data = target,target=Λ1, batchsize=500,epochs=100) #observer=obs,\n",
    "#display(Λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational tensor network: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "16-element Vector{ComplexF64}:\n",
       "  0.32694454801842465 - 0.1548999401530655im\n",
       "  0.07124964675895713 - 0.08673876713212328im\n",
       "   0.2050340029207398 + 0.1636846887527228im\n",
       "   0.2838072270609102 + 0.11967967849430342im\n",
       "  -0.2871216776588283 + 0.1906848270720099im\n",
       "  -0.1284285620990518 + 0.09408431670739281im\n",
       "   0.2742135626761631 - 0.04704482408482255im\n",
       "    0.417332269640178 + 0.038185920679627755im\n",
       " -0.25756649126832026 + 0.9006011067745788im\n",
       " -0.21632199247384862 + 0.15392591417074847im\n",
       "  0.47979967416647473 + 0.12354013212773277im\n",
       "  -0.3436374826754379 - 0.6147666368025322im\n",
       " -0.08213074248157418 - 0.3522964705002836im\n",
       "  0.10674324524442917 - 0.34429432807522825im\n",
       "  -0.9069311730367954 + 0.6885977589722938im\n",
       "  0.17932408604987046 + 0.12880516021918306im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum circuit: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "16-element Vector{ComplexF64}:\n",
       "  -0.5499955021873278 + 0.465949923028582im\n",
       "  -0.5877772297653241 - 0.0030805345936950335im\n",
       " -0.30762028875768577 + 0.06470907011427987im\n",
       " -0.16160845011106373 + 0.09984617329505466im\n",
       " -0.32422564218074956 - 0.4461071757106782im\n",
       "  0.10254679981404347 + 0.29549040358646195im\n",
       "  0.10175162088147957 + 0.6179860788000766im\n",
       " -0.29442029505836526 + 0.3450973773924977im\n",
       "  0.11750572617652132 - 0.2373181483627418im\n",
       " -0.16011981594290955 - 0.06573922664512229im\n",
       "  -0.3702641968236978 - 0.08116648536538436im\n",
       "   0.5748917658148933 + 0.6524786457793661im\n",
       "  -0.3112348684155348 - 0.09626575191139203im\n",
       "    0.287230560863912 + 0.6664957743605957im\n",
       "  -0.2605403523689795 - 0.5453049231744305im\n",
       " -0.02159105360966708 - 0.037984751016368834im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE non normalized:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.109054442521786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Λ1,Λ - quantum circuit tensor network and variational tensor network\n",
    "\n",
    "#Variational vector format\n",
    "Λmat = PastaQ.array(Λ)\n",
    "Λvec = vec(Λmat)\n",
    "\n",
    "print(\"Variational tensor network:\")\n",
    "print(\" \")\n",
    "display(Λvec)\n",
    "\n",
    "#Random circuit vector format\n",
    "Λmat1 = PastaQ.array(Λ1)\n",
    "Λvec1 = vec(Λmat1)\n",
    "\n",
    "\n",
    "print(\"Quantum circuit:\")\n",
    "print(\" \")\n",
    "display(Λvec1)\n",
    "\n",
    "MSE=0\n",
    "for i in 1:size(Λvec, 1)\n",
    "    MSE=abs(Λvec[i]*Λvec[i]-Λvec1[i]*Λvec1[i]) + MSE\n",
    "end \n",
    "\n",
    "#MSE=MSE/size(Λvec, 1)\n",
    "\n",
    "print(\"MSE non normalized:\")\n",
    "display(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aux codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThis file was not written with JLD2. Some things may not work.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ JLD2 C:\\Users\\vladl\\.julia\\packages\\JLD2\\ryhNR\\src\\JLD2.jl:379\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8×8 Matrix{NamedTuple{(:r, :i), Tuple{Float64, Float64}}}:\n",
       " (r = 0.0536476, i = 0.0)         …  (r = 0.0191324, i = 0.0351649)\n",
       " (r = 0.0288901, i = 0.100742)       (r = -0.0557315, i = 0.0548649)\n",
       " (r = 0.019322, i = -0.00733856)     (r = 0.0117011, i = 0.010048)\n",
       " (r = 0.0844858, i = 0.134043)       (r = -0.0577319, i = 0.103183)\n",
       " (r = 0.00107314, i = 0.0299312)     (r = -0.0192365, i = 0.0113778)\n",
       " (r = 0.0380839, i = 0.0178625)   …  (r = 0.00187343, i = 0.0313335)\n",
       " (r = 0.0301154, i = 0.095275)       (r = -0.0517107, i = 0.0537181)\n",
       " (r = 0.0191324, i = -0.0351649)     (r = 0.0298731, i = 0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8×8 Matrix{NamedTuple{(:r, :i), Tuple{Float64, Float64}}}:\n",
       " (r = 0.0536476, i = 0.0)         …  (r = 0.0191324, i = 0.0351649)\n",
       " (r = 0.0288901, i = 0.100742)       (r = -0.0557315, i = 0.0548649)\n",
       " (r = 0.019322, i = -0.00733856)     (r = 0.0117011, i = 0.010048)\n",
       " (r = 0.0844858, i = 0.134043)       (r = -0.0577319, i = 0.103183)\n",
       " (r = 0.00107314, i = 0.0299312)     (r = -0.0192365, i = 0.0113778)\n",
       " (r = 0.0380839, i = 0.0178625)   …  (r = 0.00187343, i = 0.0313335)\n",
       " (r = 0.0301154, i = 0.095275)       (r = -0.0517107, i = 0.0537181)\n",
       " (r = 0.0191324, i = -0.0351649)     (r = 0.0298731, i = 0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using JLD2\n",
    "\n",
    "#hello_loaded = load_object(\"dataB1.h5\")\n",
    "#display(hello_loaded)\n",
    "#hello_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the random seed so the results are the same\n",
    "# each time it is run\n",
    "#Random.seed!(1234)\n",
    "\n",
    "# Initialize the MPS state ψ = |0,0,0⟩\n",
    "#ψ = qubits(3)\n",
    "#N=3\n",
    "#nbases=3\n",
    "# Apply the X gate on qubit 2\n",
    "#g = (\"H\", 2)\n",
    "#ψ = runcircuit(ψ, g)\n",
    "#bases= randombases(N, nbases)\n",
    "#A=getsamples(ψ,bases)\n",
    "#display(A)\n",
    "\n",
    "# Show samples from P(x) = |⟨H|ψ⟩|²\n",
    "#println(\"Sample from |ψ⟩ = H2|0,0,0⟩:\")\n",
    "#display(getsamples(ψ, 50))\n",
    "#println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Small amount of code to understand page 14 of article\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"Small amount of code to understand page 14 of article\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplexF64[0.9999999962212077 - 7.132082919106261e-19im 3.0797378536284725e-12 + 1.4025551553498161e-12im -2.7143010061791983e-12 + 8.54011306117286e-13im 4.598169067726587e-12 - 1.588958999099166e-12im; 1.8848880789512634e-12 - 1.4026280137358071e-12im 0.9999999962178888 - 1.7384894854275448e-19im -4.5314446639466155e-13 - 3.5324937419645153e-12im 2.3620203015717323e-12 - 2.743430482787801e-12im; -1.6474044350900385e-12 - 8.539835505416704e-13im -2.6251917306652217e-13 + 3.532424353025476e-12im 0.9999999962144832 + 2.398336817571067e-19im -1.6988563333875106e-12 + 1.0667786098927934e-12im; 2.7987473449897493e-12 + 1.5890405311025368e-12im 1.440033856048295e-12 + 2.7433749716365696e-12im -1.0167144903761027e-12 - 1.0667751404458414e-12im 0.9999999962089026 + 4.1470421878276345e-19im]\u001b[0m\u001b[1mTest Summary:                     | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1m   Time\u001b[22m\n",
      "Trace preserving condition in QPT | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m1m32.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"Trace preserving condition in QPT\", Any[], 1, false, false, true, 1.690718730347e9, 1.690718822843e9, false)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#@testset \"Trace preserving condition in QPT\" begin\n",
    "#  Random.seed!(1234)\n",
    "#  N = 2\n",
    "#  d = 1 << N\n",
    "#  nshots = 3\n",
    "#  gates = randomcircuit(N; depth=4)\n",
    "#  Λ = runcircuit(gates; process=true, noise=(\"DEP\", (p=0.001,)))\n",
    "#  preps = fullpreparations(N)\n",
    "#  bases = fullbases(N)\n",
    "#  data = getsamples(Λ, preps, bases, nshots)\n",
    "\n",
    "#  ρ = tomography(data; method=\"LS\")\n",
    "#  for j in 1:N\n",
    "#    s = firstind(ρ; tags=\"Output,n=$(j)\", plev=0)\n",
    "#    ρ = ρ * δ(s, s')\n",
    "#  end\n",
    "\n",
    "#  ρmat = PastaQ.array(ρ)\n",
    "#  @test ρmat ≈ Matrix{Float64}(I, d, d) atol = 1e-5\n",
    "#  print(ρmat)\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Choi POVM matrix generation (Which is interesting to generate the ideal one)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"Choi POVM matrix generation (Which is interesting to generate the ideal one)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=699|\"Output,Qubit,Site,n=1\")', (dim=2|id=699|\"Input,Qubit,Site,n=1\")', (dim=2|id=699|\"Input,Qubit,Site,n=1\"), (dim=2|id=699|\"Output,Qubit,Site,n=1\"), (dim=16|id=347|\"Link,n=1\"))\n",
       "[2] ((dim=16|id=347|\"Link,n=1\"), (dim=2|id=938|\"Output,Qubit,Site,n=2\")', (dim=2|id=938|\"Input,Qubit,Site,n=2\")', (dim=2|id=938|\"Input,Qubit,Site,n=2\"), (dim=2|id=938|\"Output,Qubit,Site,n=2\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "16×16 Matrix{ComplexF64}:\n",
       "  0.0223131-2.17749e-16im  …  -0.0327512+0.0818046im\n",
       " 0.00525756+0.125749im          -0.48021-0.169344im\n",
       "  0.0559976-0.0259519im        0.0132691+0.249348im\n",
       "  0.0475101+0.0302805im        -0.185174+0.132912im\n",
       " 0.00488541-0.0430422im         0.154318+0.0830728im\n",
       " -0.0397098-0.0443346im    …    0.226231-0.0824806im\n",
       "  0.0471282+0.0846894im        -0.388956+0.0496612im\n",
       "  0.0701614-0.0208397im       -0.0272306+0.294859im\n",
       " -0.0747876-0.0666008im         0.362608-0.180748im\n",
       " -0.0268152+0.0413275im        -0.114901-0.162861im\n",
       " -0.0678064+0.0531363im    …  -0.0976148-0.334579im\n",
       "  0.0170108-0.00166892im      -0.0193112+0.0664013im\n",
       "  0.0377276+0.0527706im        -0.254935+0.0623501im\n",
       " -0.0352955+0.0618375im        -0.179183-0.225554im\n",
       " -0.0271547+0.0742852im        -0.238178-0.213696im\n",
       " -0.0327512-0.0818046im    …    0.357035+1.72605e-16im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "256-element Vector{ComplexF64}:\n",
       "   0.02231312177389383 - 2.1774873620120754e-16im\n",
       " 0.0052575631049269714 + 0.12574854793199217im\n",
       "   0.05599764275921061 - 0.025951948464004164im\n",
       "   0.04751010711225735 + 0.030280521992698133im\n",
       "  0.004885414050270766 - 0.04304219473987845im\n",
       "  -0.03970979276381297 - 0.044334605207493216im\n",
       "   0.04712815080474611 + 0.08468940158017196im\n",
       "   0.07016140536833959 - 0.020839708616552384im\n",
       "  -0.07478757325248499 - 0.06660081319210624im\n",
       " -0.026815219393898495 + 0.0413275172245548im\n",
       "   -0.0678063757382372 + 0.05313631799680475im\n",
       "  0.017010848374858206 - 0.0016689248347860118im\n",
       "    0.0377275596200684 + 0.052770623685218725im\n",
       "                       ⋮\n",
       "   0.15431754959901686 + 0.08307280284670826im\n",
       "   0.22623054865434103 - 0.08248064298669858im\n",
       "   -0.3889558444314604 + 0.04966115573066174im\n",
       " -0.027230562161878046 + 0.2948590750502604im\n",
       "   0.36260828812054346 - 0.18074846075084214im\n",
       "  -0.11490099943853264 - 0.16286141365890872im\n",
       "     -0.09761483842794 - 0.33457884301494817im\n",
       "  -0.01931120371339367 + 0.0664013056210589im\n",
       "   -0.2549349913630755 + 0.06235007160646211im\n",
       "  -0.17918339360472668 - 0.2255543278762477im\n",
       "    -0.238177646979845 - 0.2136956533532416im\n",
       "     0.357034861495773 + 1.726049858596923e-16im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dict{Tuple, Dict{Tuple, Float64}} with 81 entries:\n",
       "  (\"Z\", \"Y\", \"Y\", \"Z\") => Dict((1, 1, 1, 0)=>0.0833333, (0, 1, 1, 0)=>0.0833333…\n",
       "  (\"X\", \"Y\", \"X\", \"Y\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0, (1, 0, 0, …\n",
       "  (\"Y\", \"Z\", \"Y\", \"Y\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.166667, (1, 0…\n",
       "  (\"Y\", \"Y\", \"Z\", \"Z\") => Dict((1, 1, 1, 0)=>0.166667, (1, 0, 0, 1)=>0.0833333,…\n",
       "  (\"Z\", \"X\", \"X\", \"Y\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0, (1, 0, 0, …\n",
       "  (\"Z\", \"Z\", \"X\", \"X\") => Dict((1, 1, 1, 0)=>0.0833333, (0, 1, 1, 0)=>0.0833333…\n",
       "  (\"X\", \"Z\", \"X\", \"Z\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0, (1, 0, 0, …\n",
       "  (\"Z\", \"X\", \"Z\", \"Y\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0833333, (1, …\n",
       "  (\"Y\", \"Y\", \"Y\", \"Y\") => Dict((1, 1, 1, 0)=>0.0833333, (0, 1, 1, 0)=>0.0833333…\n",
       "  (\"Z\", \"Z\", \"Y\", \"X\") => Dict((1, 1, 1, 0)=>0.166667, (0, 1, 1, 0)=>0.166667, …\n",
       "  (\"X\", \"Z\", \"Z\", \"Z\") => Dict((1, 1, 1, 0)=>0.166667, (0, 1, 1, 0)=>0.25, (1, …\n",
       "  (\"X\", \"Z\", \"Y\", \"Z\") => Dict((1, 1, 1, 0)=>0.166667, (0, 1, 1, 0)=>0.166667, …\n",
       "  (\"X\", \"X\", \"Y\", \"X\") => Dict((1, 1, 1, 0)=>0.0833333, (1, 0, 0, 1)=>0.0833333…\n",
       "  (\"Y\", \"Y\", \"Y\", \"Z\") => Dict((1, 1, 1, 0)=>0.0833333, (1, 0, 0, 1)=>0.0833333…\n",
       "  (\"X\", \"Y\", \"X\", \"X\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0, (1, 0, 0, …\n",
       "  (\"X\", \"X\", \"Z\", \"X\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0, (1, 0, 0, …\n",
       "  (\"Y\", \"X\", \"Y\", \"Y\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0, (1, 0, 0, …\n",
       "  (\"X\", \"Y\", \"Y\", \"X\") => Dict((1, 1, 1, 0)=>0.166667, (1, 0, 0, 1)=>0.166667, …\n",
       "  (\"Z\", \"Y\", \"Z\", \"Y\") => Dict((1, 1, 1, 0)=>0.0, (1, 0, 0, 1)=>0.0833333, (0, …\n",
       "  (\"Z\", \"Y\", \"X\", \"Y\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.0833333, (1, …\n",
       "  (\"Y\", \"Y\", \"X\", \"Z\") => Dict((1, 1, 1, 0)=>0.0, (0, 1, 1, 0)=>0.166667, (1, 0…\n",
       "  (\"Y\", \"X\", \"X\", \"Z\") => Dict((1, 1, 1, 0)=>0.166667, (0, 1, 1, 0)=>0.0833333,…\n",
       "  (\"Y\", \"Z\", \"Y\", \"Z\") => Dict((1, 1, 1, 0)=>0.25, (1, 0, 0, 1)=>0.166667, (0, …\n",
       "  (\"X\", \"Z\", \"Y\", \"Y\") => Dict((1, 1, 1, 0)=>0.0833333, (0, 1, 1, 0)=>0.0833333…\n",
       "  (\"Z\", \"Y\", \"Y\", \"X\") => Dict((1, 1, 1, 0)=>0.166667, (0, 1, 1, 0)=>0.25, (1, …\n",
       "  ⋮                    => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1296×256 Matrix{ComplexF64}:\n",
       "    0.0-0.0im  0.0-0.0im     0.0+0.0im     …  0.0-0.0im        0.0-0.0im\n",
       "   0.25-0.0im  0.0-0.0im     0.0+0.25im       0.0-0.0im        0.0-0.0im\n",
       "    0.0-0.0im  0.0-0.0im     0.0-0.0im        0.0-0.0im       0.25-0.0im\n",
       "    0.0-0.0im  0.0-0.0im     0.0-0.0im        0.0-0.0im        0.0-0.0im\n",
       "    0.0+0.0im  0.0+0.0im     0.0-0.0im        0.0+0.0im       0.25+0.0im\n",
       "    0.0+0.0im  0.0+0.0im     0.0-0.0im     …  0.0+0.0im        0.0+0.0im\n",
       "    0.0-0.0im  0.0-0.0im     0.0-0.0im        0.0-0.0im        0.0-0.0im\n",
       "   0.25-0.0im  0.0-0.0im     0.0-0.25im       0.0-0.0im        0.0-0.0im\n",
       "    0.0-0.0im  0.0-0.0im     0.0-0.0im        0.0-0.0im       0.25-0.0im\n",
       "    0.0+0.0im  0.0+0.0im     0.0-0.0im        0.0+0.0im        0.0+0.0im\n",
       "    0.0-0.0im  0.0-0.0im     0.0+0.0im     …  0.0-0.0im        0.0-0.0im\n",
       "   0.25+0.0im  0.0+0.0im     0.0-0.25im       0.0+0.0im        0.0+0.0im\n",
       "    0.0-0.0im  0.0-0.0im     0.0+0.0im        0.0-0.0im       0.25-0.0im\n",
       "       ⋮                                   ⋱                      ⋮\n",
       " 0.0625+0.0im  0.0+0.0625im  0.0-0.0625im     0.0-0.0625im  0.0625+0.0im\n",
       " 0.0625+0.0im  0.0+0.0625im  0.0-0.0625im  …  0.0-0.0625im  0.0625+0.0im\n",
       " 0.0625-0.0im  0.0-0.0625im  0.0-0.0625im     0.0+0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0-0.0625im  0.0-0.0625im     0.0+0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0+0.0625im  0.0+0.0625im     0.0-0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0-0.0625im  0.0-0.0625im     0.0+0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0+0.0625im  0.0+0.0625im  …  0.0-0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0-0.0625im  0.0-0.0625im     0.0+0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0+0.0625im  0.0+0.0625im     0.0-0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0+0.0625im  0.0+0.0625im     0.0-0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0-0.0625im  0.0+0.0625im     0.0+0.0625im  0.0625-0.0im\n",
       " 0.0625-0.0im  0.0-0.0625im  0.0+0.0625im  …  0.0+0.0625im  0.0625-0.0im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Choi POVM matrix | \u001b[32m   1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m4.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"Choi POVM matrix\", Any[], 1, false, false, true, 1.690718823486e9, 1.690718827889e9, false)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@testset \"Choi POVM matrix\" begin\n",
    "  N = 2\n",
    "  d = 2^(2 * N)\n",
    "  nshots = 3\n",
    "  gates = randomcircuit(N; depth=2)\n",
    "\n",
    "  Λ = runcircuit(gates; process=true, noise=(\"DEP\", (p=0.001,)))\n",
    "  preps = fullpreparations(N)\n",
    "  bases = fullbases(N)\n",
    "  data = getsamples(Λ, preps, bases, nshots)\n",
    "  \n",
    "  display(Λ)\n",
    "  Λmat = PastaQ.array(Λ)\n",
    "  display(Λmat)\n",
    "  Λvec = vec(Λmat)\n",
    "  display(Λvec)\n",
    "\n",
    "  probs = PastaQ.empirical_probabilities(data)\n",
    "  display(probs)\n",
    "\n",
    "  A = PastaQ.design_matrix(probs; return_probs=false, process=true)#\n",
    "  display(A)\n",
    "\n",
    "  real_probs = A * Λvec\n",
    "  Λ̂vec = pinv(A) * real_probs\n",
    "  Λ̂ = reshape(Λ̂vec, (d, d))\n",
    "  @test Λmat ≈ Λ̂\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stoptomography_ifloss (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function stomography(\n",
    "  data::Matrix{Pair{String,Int}};\n",
    "  method::String=\"linear_inversion\",\n",
    "  fillzeros::Bool=true,\n",
    "  kwargs...,\n",
    ")\n",
    "  return stomography(\n",
    "    empirical_probabilities(data; fillzeros=fillzeros),\n",
    "    siteinds(\"Qubit\", size(data, 2));\n",
    "    method=method,\n",
    "    kwargs...,\n",
    "  )\n",
    "end\n",
    "\n",
    "function stomography(\n",
    "  data::Matrix{Pair{String,Int}},\n",
    "  sites::Vector{<:Index};\n",
    "  method::String=\"linear_inversion\",\n",
    "  fillzeros::Bool=true,\n",
    "  kwargs...,\n",
    ")\n",
    "  return stomography(\n",
    "    empirical_probabilities(data; fillzeros=fillzeros), sites; method=method, kwargs...\n",
    "  )\n",
    "end\n",
    "\n",
    "function stomography(data::Matrix{Pair{String,Pair{String,Int}}}; kwargs...)\n",
    "  return stomography(data, siteinds(\"Qubit\", size(data, 2)); kwargs...)\n",
    "end\n",
    "\n",
    "function stomography(\n",
    "  data::Matrix{Pair{String,Pair{String,Int}}},\n",
    "  sites::Vector{<:Index};\n",
    "  method::String=\"linear_inversion\",\n",
    "  fillzeros::Bool=true,\n",
    "  kwargs...,\n",
    ")\n",
    "  sites_in = addtags.(sites, \"Input\")\n",
    "  sites_out = addtags.(sites, \"Output\")\n",
    "  process_sites = Index[]\n",
    "  for j in 1:size(data, 2)\n",
    "    push!(process_sites, sites_in[j])\n",
    "    push!(process_sites, sites_out[j])\n",
    "  end\n",
    "  return stomography(\n",
    "    empirical_probabilities(data; fillzeros=fillzeros),\n",
    "    process_sites;\n",
    "    method=method,\n",
    "    process=true,\n",
    "    kwargs...,\n",
    "  )\n",
    "end\n",
    "\n",
    "\n",
    "function stomography(train_data::AbstractMatrix, L::LPDO; (observer!)=nothing, kwargs...)\n",
    "  # Read arguments\n",
    "  opt = get(kwargs, :optimizer, Optimisers.Descent(0.01))\n",
    "  batchsize::Int64 = get(kwargs, :batchsize, 100)\n",
    "  epochs::Int64 = get(kwargs, :epochs, 1000)\n",
    "  trace_preserving_regularizer = get(kwargs, :trace_preserving_regularizer, 0.0)\n",
    "  observe_step::Int64 = get(kwargs, :observe_step, 1)\n",
    "  test_data = get(kwargs, :test_data, nothing)\n",
    "  print_metrics = get(kwargs, :print_metrics, [])\n",
    "  outputpath = get(kwargs, :outputpath, nothing)\n",
    "  outputlevel = get(kwargs, :outputlevel, 1)\n",
    "  savestate = get(kwargs, :savestate, false)\n",
    "  earlystop = get(kwargs, :earlystop, false)\n",
    "\n",
    "  model = copy(L)\n",
    "  isqpt = train_data isa Matrix{Pair{String,Pair{String,Int}}}\n",
    "  localnorm = isqpt ? 2.0 : 1.0\n",
    "  print(\" \")\n",
    "  print(test_data)\n",
    "  print(\" \")\n",
    "  print(\"Bananas:\")\n",
    "  println()\n",
    "\n",
    "  # observer is not passed but earlystop is called\n",
    "  observer! = (isnothing(observer!) || earlystop) ? Observer() : observer!\n",
    "\n",
    "  # observer is defined\n",
    "  if !isnothing(observer!)\n",
    "    observer![\"train_loss\"] = nothing\n",
    "    if !isnothing(test_data)\n",
    "      observer![\"test_loss\"] = nothing\n",
    "    end\n",
    "    # add the standard early stop function to the observer\n",
    "    if earlystop\n",
    "      function stop_if(; loss::Vector)\n",
    "        return stoptomography_ifloss(; loss=loss, ϵ=1e-3, min_iter=50, window=50)\n",
    "      end\n",
    "      observer![\"earlystop\"] = stop_if\n",
    "    end\n",
    "  end\n",
    "\n",
    "  # initialize optimizer\n",
    "  st = PastaQ.state(opt, model)\n",
    "  optimizer = (opt, st)\n",
    "\n",
    "  @assert size(train_data, 2) == length(model)\n",
    "  !isnothing(test_data) && @assert size(test_data)[2] == length(model)\n",
    "\n",
    "  batchsize = min(size(train_data)[1], batchsize)\n",
    "  num_batches = Int(floor(size(train_data)[1] / batchsize))\n",
    "\n",
    "  tot_time = 0.0\n",
    "  observe_time = 0.0\n",
    "  best_model = nothing\n",
    "  best_testloss = 1000.0\n",
    "  test_loss = nothing\n",
    "\n",
    "  # Training iterations\n",
    "  for ep in 1:epochs\n",
    "    ep_time = @elapsed begin\n",
    "      train_data = train_data[shuffle(1:end), :]\n",
    "      train_loss = 0.0\n",
    "\n",
    "      # Sweep over the data set\n",
    "      for b in 1:num_batches\n",
    "        batch = train_data[((b - 1) * batchsize + 1):(b * batchsize), :]\n",
    "\n",
    "        normalized_model = copy(model)\n",
    "        sqrt_localnorms = []\n",
    "        PastaQ.normalize!(\n",
    "          normalized_model; (sqrt_localnorms!)=sqrt_localnorms, localnorm=localnorm\n",
    "        )\n",
    "\n",
    "        grads, loss = PastaQ.gradients(\n",
    "          normalized_model,\n",
    "          batch;\n",
    "          sqrt_localnorms=sqrt_localnorms,\n",
    "          trace_preserving_regularizer=trace_preserving_regularizer,\n",
    "        )\n",
    "\n",
    "        nupdate = ep * num_batches + b\n",
    "        train_loss += loss / Float64(num_batches)\n",
    "        update!(model, grads, optimizer)\n",
    "      end\n",
    "    end # end @elapsed\n",
    "    !isnothing(observer!) && push!(last(observer![\"train_loss\"]), train_loss)\n",
    "    observe_time += ep_time\n",
    "\n",
    "    # measurement stage\n",
    "    if ep % observe_step == 0\n",
    "      normalized_model = copy(model)\n",
    "      sqrt_localnorms = []\n",
    "      PastaQ.normalize!(normalized_model; (sqrt_localnorms!)=sqrt_localnorms, localnorm=localnorm)\n",
    "\n",
    "      if !isnothing(test_data)\n",
    "        test_loss = nll(normalized_model, test_data)\n",
    "        !isnothing(observer!) && push!(last(observer![\"test_loss\"]), test_loss)\n",
    "        if test_loss ≤ best_testloss\n",
    "          best_testloss = test_loss\n",
    "          best_model = copy(normalized_model)\n",
    "        end\n",
    "      else\n",
    "        best_model = copy(normalized_model)\n",
    "      end\n",
    "\n",
    "      # update observer\n",
    "      if !isnothing(observer!)\n",
    "        loss = (\n",
    "          if !isnothing(test_data)\n",
    "            results(observer!, \"test_loss\")\n",
    "          else\n",
    "            results(observer!, \"train_loss\")\n",
    "          end\n",
    "        )\n",
    "\n",
    "        model_to_observe = (\n",
    "          if isqpt && (normalized_model isa LPDO{MPS})\n",
    "            PastaQ.choi_mps_to_unitary_mpo(normalized_model)\n",
    "          elseif !isqpt && (normalized_model isa LPDO{MPS})\n",
    "            normalized_model.X\n",
    "          else\n",
    "            normalized_model\n",
    "          end\n",
    "        )\n",
    "        update!(\n",
    "          observer!, model_to_observe; train_loss=train_loss, test_loss=test_loss, loss=loss\n",
    "        )\n",
    "        tot_time += observe_time\n",
    "      end\n",
    "\n",
    "      # printing\n",
    "        \n",
    "      if outputlevel ≥ 1\n",
    "        #print(\"%d  \", ep)\n",
    "        print(train_loss)\n",
    "        print(\",\")\n",
    "        print(\"testloss:\")\n",
    "        print(test_loss)\n",
    "        if !isnothing(test_data)\n",
    "          print(\"(%d)  \", test_loss)\n",
    "        end\n",
    "        # TODO: add the trace preserving cost function here for QPT\n",
    "        !isnothing(observer!) && PastaQ.printobserver(observer!, print_metrics)\n",
    "        #print(\"elapsed = %d\", observe_time)\n",
    "        observe_time = 0.0\n",
    "        print(\"\")\n",
    "      end\n",
    "      # saving\n",
    "      if !isnothing(outputpath)\n",
    "        observerpath = outputpath * \"_observer.jld2\"\n",
    "        save(observerpath, observer!)\n",
    "        if savestate\n",
    "          if isqpt\n",
    "            model_to_be_saved =\n",
    "              model isa LPDO{MPS} ? PastaQ.choi_mps_to_unitary_mpo(best_model) : best_model\n",
    "          else\n",
    "            model_to_be_saved = model isa LPDO{MPS} ? best_model.X : best_model\n",
    "          end\n",
    "          statepath = outputpath * \"_state.h5\"\n",
    "          h5rewrite(statepath) do fout\n",
    "            write(fout, \"state\", model_to_be_saved)\n",
    "          end\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "    !isnothing(observer!) &&\n",
    "      haskey(observer!.data, \"earlystop\") &&\n",
    "      results(observer!, \"earlystop\")[end] &&\n",
    "      break\n",
    "  end\n",
    "  return best_model\n",
    "end\n",
    "\n",
    "# QST\n",
    "function stomography(data::Matrix{Pair{String,Int}}, ψ::MPS; kwargs...)\n",
    "  return stomography(data, LPDO(ψ); kwargs...).X\n",
    "end\n",
    "\n",
    "function stomography(train_data::Vector{<:Vector{Pair{String,Int}}}, args...; kwargs...)\n",
    "  return stomography(permutedims(hcat(train_data...)), args...; kwargs...)\n",
    "end\n",
    "\n",
    "# QPT###################################################################################### passes here\n",
    "function stomography(data::Matrix{Pair{String,Pair{String,Int}}}, U::MPO; kwargs...)\n",
    "  return PastaQ.choi_mps_to_unitary_mpo(\n",
    "    stomography(data, LPDO(PastaQ.unitary_mpo_to_choi_mps(U)); kwargs...)\n",
    "  )\n",
    "end\n",
    "\n",
    "function stomography(\n",
    "  train_data::Vector{<:Vector{Pair{String,Pair{String,Int}}}}, args...; kwargs...\n",
    ")\n",
    "  return stomography(permutedims(hcat(train_data...)), args...; kwargs...)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "EARLY STOPPING FUNCTIONS\n",
    "\"\"\"\n",
    "\n",
    "#stopif_fidelity(M1, M2; ϵ::Number, kwargs...)\n",
    "#  fidelity(M1,M2) ≤ ϵ\n",
    "\n",
    "function stoptomography_ifloss(; loss::Vector, ϵ::Number, min_iter::Number, window::Number)\n",
    "  length(loss) < min_iter + 1 && return false\n",
    "  length(loss) < window && return false\n",
    "  avgloss = StatsBase.mean(loss[(end - window):end])\n",
    "  Δ = StatsBase.sem(loss[(end - window):end])\n",
    "  return Δ / avgloss < ϵ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run circuit MPO:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=518|\"Qubit,Site,n=1\")', (dim=2|id=518|\"Qubit,Site,n=1\"), (dim=4|id=866|\"Link,n=1\"))\n",
       "[2] ((dim=4|id=866|\"Link,n=1\"), (dim=2|id=392|\"Qubit,Site,n=2\")', (dim=2|id=392|\"Qubit,Site,n=2\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1:---------------------------------------------------------------------------This is U0:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=518|\"Qubit,Site,n=1\")', (dim=4|id=839|\"Link,l=1\"), (dim=2|id=518|\"Qubit,Site,n=1\"))\n",
       "[2] ((dim=2|id=392|\"Qubit,Site,n=2\")', (dim=4|id=839|\"Link,l=1\"), (dim=2|id=392|\"Qubit,Site,n=2\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2---------------------------------------------Part 3---------------------------------------------1     ⟨logP⟩ = 3.2787  (1.6531)  elapsed = 18.507s\n",
      "2     ⟨logP⟩ = 3.1294  (1.6580)  elapsed = 0.225s\n",
      "3     ⟨logP⟩ = 3.0074  (1.6693)  elapsed = 0.200s\n",
      "4     ⟨logP⟩ = 2.8857  (1.6980)  elapsed = 0.175s\n",
      "5     ⟨logP⟩ = 2.7772  (1.7921)  elapsed = 0.170s\n",
      "6     ⟨logP⟩ = 2.6707  (1.8855)  elapsed = 0.159s\n",
      "7     ⟨logP⟩ = 2.5860  (1.7371)  elapsed = 0.185s\n",
      "8     ⟨logP⟩ = 2.5310  (1.7100)  elapsed = 0.159s\n",
      "9     ⟨logP⟩ = 2.4777  (1.7189)  elapsed = 0.182s\n",
      "10    ⟨logP⟩ = 2.4398  (1.7273)  elapsed = 0.180s\n",
      "11    ⟨logP⟩ = 2.4221  (1.7165)  elapsed = 0.167s\n",
      "12    ⟨logP⟩ = 2.3985  (1.7171)  elapsed = 0.164s\n",
      "13    ⟨logP⟩ = 2.3743  (1.7218)  elapsed = 0.166s\n",
      "14    ⟨logP⟩ = 2.3651  (1.7318)  elapsed = 0.165s\n",
      "15    ⟨logP⟩ = 2.3670  (1.7466)  elapsed = 0.167s\n",
      "16    ⟨logP⟩ = 2.3595  (1.7626)  elapsed = 0.159s\n",
      "17    ⟨logP⟩ = 2.3414  (1.7839)  elapsed = 0.163s\n",
      "18    ⟨logP⟩ = 2.3502  (1.7772)  elapsed = 0.151s\n",
      "19    ⟨logP⟩ = 2.3499  (1.7424)  elapsed = 0.151s\n",
      "20    ⟨logP⟩ = 2.3461  (1.7172)  elapsed = 0.165s\n",
      "21    ⟨logP⟩ = 2.3404  (1.6916)  elapsed = 0.160s\n",
      "22    ⟨logP⟩ = 2.3245  (1.6540)  elapsed = 0.171s\n",
      "23    ⟨logP⟩ = 2.3284  (1.6137)  elapsed = 0.153s\n",
      "24    ⟨logP⟩ = 2.3136  (1.5943)  elapsed = 0.150s\n",
      "25    ⟨logP⟩ = 2.2960  (1.6320)  elapsed = 0.158s\n",
      "26    ⟨logP⟩ = 2.2828  (1.7105)  elapsed = 0.151s\n",
      "27    ⟨logP⟩ = 2.2715  (1.8086)  elapsed = 0.173s\n",
      "28    ⟨logP⟩ = 2.2727  (1.8800)  elapsed = 0.151s\n",
      "29    ⟨logP⟩ = 2.2487  (1.9058)  elapsed = 0.152s\n",
      "30    ⟨logP⟩ = 2.2616  (1.8859)  elapsed = 0.157s\n",
      "31    ⟨logP⟩ = 2.2399  (1.8307)  elapsed = 0.161s\n",
      "32    ⟨logP⟩ = 2.2319  (1.7758)  elapsed = 0.151s\n",
      "33    ⟨logP⟩ = 2.2157  (1.7290)  elapsed = 0.178s\n",
      "34    ⟨logP⟩ = 2.2065  (1.6889)  elapsed = 0.156s\n",
      "35    ⟨logP⟩ = 2.1892  (1.6514)  elapsed = 0.161s\n",
      "36    ⟨logP⟩ = 2.1870  (1.6125)  elapsed = 0.172s\n",
      "37    ⟨logP⟩ = 2.1831  (1.5737)  elapsed = 0.191s\n",
      "38    ⟨logP⟩ = 2.1794  (1.5408)  elapsed = 0.156s\n",
      "39    ⟨logP⟩ = 2.1612  (1.5223)  elapsed = 0.149s\n",
      "40    ⟨logP⟩ = 2.1584  (1.5241)  elapsed = 0.149s\n",
      "41    ⟨logP⟩ = 2.1511  (1.5441)  elapsed = 0.153s\n",
      "42    ⟨logP⟩ = 2.1431  (1.5415)  elapsed = 0.145s\n",
      "43    ⟨logP⟩ = 2.1346  (1.5144)  elapsed = 0.150s\n",
      "44    ⟨logP⟩ = 2.1363  (1.4987)  elapsed = 0.152s\n",
      "45    ⟨logP⟩ = 2.1166  (1.4920)  elapsed = 0.150s\n",
      "46    ⟨logP⟩ = 2.1134  (1.4856)  elapsed = 0.152s\n",
      "47    ⟨logP⟩ = 2.0999  (1.4787)  elapsed = 0.143s\n",
      "48    ⟨logP⟩ = 2.0959  (1.4687)  elapsed = 0.147s\n",
      "49    ⟨logP⟩ = 2.0942  (1.4596)  elapsed = 0.154s\n",
      "50    ⟨logP⟩ = 2.0926  (1.4533)  elapsed = 0.157s\n",
      "51    ⟨logP⟩ = 2.0883  (1.4553)  elapsed = 0.157s\n",
      "52    ⟨logP⟩ = 2.0819  (1.4593)  elapsed = 0.147s\n",
      "53    ⟨logP⟩ = 2.0746  (1.4642)  elapsed = 0.151s\n",
      "54    ⟨logP⟩ = 2.0771  (1.4803)  elapsed = 0.144s\n",
      "55    ⟨logP⟩ = 2.0610  (1.5030)  elapsed = 0.146s\n",
      "56    ⟨logP⟩ = 2.0615  (1.5299)  elapsed = 0.155s\n",
      "57    ⟨logP⟩ = 2.0572  (1.5558)  elapsed = 0.152s\n",
      "58    ⟨logP⟩ = 2.0501  (1.5827)  elapsed = 0.148s\n",
      "59    ⟨logP⟩ = 2.0449  (1.6025)  elapsed = 0.148s\n",
      "60    ⟨logP⟩ = 2.0370  (1.6066)  elapsed = 0.154s\n",
      "61    ⟨logP⟩ = 2.0402  (1.6013)  elapsed = 0.143s\n",
      "62    ⟨logP⟩ = 2.0355  (1.5860)  elapsed = 0.143s\n",
      "63    ⟨logP⟩ = 2.0277  (1.5635)  elapsed = 0.150s\n",
      "64    ⟨logP⟩ = 2.0355  (1.5433)  elapsed = 0.147s\n",
      "65    ⟨logP⟩ = 2.0259  (1.5260)  elapsed = 0.154s\n",
      "66    ⟨logP⟩ = 2.0286  (1.5102)  elapsed = 0.147s\n",
      "67    ⟨logP⟩ = 2.0214  (1.4974)  elapsed = 0.145s\n",
      "68    ⟨logP⟩ = 2.0140  (1.5017)  elapsed = 0.148s\n",
      "69    ⟨logP⟩ = 2.0172  (1.5187)  elapsed = 0.144s\n",
      "70    ⟨logP⟩ = 2.0166  (1.5401)  elapsed = 0.163s\n",
      "71    ⟨logP⟩ = 2.0161  (1.5677)  elapsed = 0.139s\n",
      "72    ⟨logP⟩ = 2.0109  (1.6018)  elapsed = 0.146s\n",
      "73    ⟨logP⟩ = 2.0142  (1.6341)  elapsed = 0.146s\n",
      "74    ⟨logP⟩ = 2.0047  (1.6437)  elapsed = 0.144s\n",
      "75    ⟨logP⟩ = 2.0059  (1.6503)  elapsed = 0.150s\n",
      "76    ⟨logP⟩ = 2.0029  (1.6484)  elapsed = 0.145s\n",
      "77    ⟨logP⟩ = 2.0081  (1.6424)  elapsed = 0.151s\n",
      "78    ⟨logP⟩ = 2.0127  (1.6473)  elapsed = 0.144s\n",
      "79    ⟨logP⟩ = 2.0086  (1.6542)  elapsed = 0.144s\n",
      "80    ⟨logP⟩ = 2.0080  (1.6572)  elapsed = 0.157s\n",
      "81    ⟨logP⟩ = 2.0046  (1.6592)  elapsed = 0.143s\n",
      "82    ⟨logP⟩ = 2.0092  (1.6641)  elapsed = 0.140s\n",
      "83    ⟨logP⟩ = 2.0033  (1.6707)  elapsed = 0.147s\n",
      "84    ⟨logP⟩ = 2.0047  (1.6807)  elapsed = 0.146s\n",
      "85    ⟨logP⟩ = 1.9911  (1.7005)  elapsed = 0.145s\n",
      "86    ⟨logP⟩ = 2.0064  (1.7205)  elapsed = 0.143s\n",
      "87    ⟨logP⟩ = 1.9940  (1.7143)  elapsed = 0.141s\n",
      "88    ⟨logP⟩ = 1.9993  (1.7037)  elapsed = 0.142s\n",
      "89    ⟨logP⟩ = 1.9980  (1.6917)  elapsed = 0.156s\n",
      "90    ⟨logP⟩ = 2.0115  (1.6742)  elapsed = 0.146s\n",
      "91    ⟨logP⟩ = 1.9936  (1.6583)  elapsed = 0.177s\n",
      "92    ⟨logP⟩ = 2.0016  (1.6449)  elapsed = 0.147s\n",
      "93    ⟨logP⟩ = 1.9951  (1.6314)  elapsed = 0.149s\n",
      "94    ⟨logP⟩ = 1.9940  (1.6196)  elapsed = 0.147s\n",
      "95    ⟨logP⟩ = 1.9988  (1.6096)  elapsed = 0.145s\n",
      "96    ⟨logP⟩ = 1.9956  (1.6025)  elapsed = 0.145s\n",
      "97    ⟨logP⟩ = 1.9975  (1.5966)  elapsed = 0.152s\n",
      "98    ⟨logP⟩ = 1.9932  (1.5918)  elapsed = 0.151s\n",
      "99    ⟨logP⟩ = 2.0027  (1.5860)  elapsed = 0.157s\n",
      "100   ⟨logP⟩ = 1.9941  (1.5811)  elapsed = 0.150s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=518|\"Qubit,Site,n=1\")', (dim=4|id=839|\"Link,l=1\"), (dim=2|id=518|\"Qubit,Site,n=1\"))\n",
       "[2] ((dim=2|id=392|\"Qubit,Site,n=2\")', (dim=4|id=839|\"Link,l=1\"), (dim=2|id=392|\"Qubit,Site,n=2\"))\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PastaQ\n",
    "using Random\n",
    "using ITensors\n",
    "using Observers\n",
    "using Optimisers: Optimisers\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "using SCS\n",
    "using Convex\n",
    "\n",
    "N = 2\n",
    "nshots = 1\n",
    "gates = randomcircuit(N; depth=10)\n",
    "Λ1 = runcircuit(gates; process=true)\n",
    "\n",
    "print(\"Run circuit MPO:\")\n",
    "display(Λ1)\n",
    "\n",
    "#For training data\n",
    "preps = randompreparations(N,4) #random initialization of states\n",
    "bases = randombases(N,4)        #random basis of measurements\n",
    "data = getsamples(Λ1, preps, bases,100) #Get samples for these datapoints accordingly to the preparation and basis\n",
    "\n",
    "#For testing data\n",
    "preps = randompreparations(N,4)\n",
    "bases = randombases(N,4)\n",
    "target = getsamples(Λ1, preps, bases, 2)\n",
    "\n",
    "print(\"Part 1:----------------------------------\")\n",
    "#display(data)\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "χ = maxlinkdim(Λ1) #\n",
    "U0 = randomprocess(Λ1,mixed=false; χ=χ) #definition of the variational circuit\n",
    "print(\"This is U0:\")\n",
    "display(U0)\n",
    "print(\"Part 2---------------------------------------------\")\n",
    "\n",
    "#F(bu::LPDO; kwargs...) = fidelity(bu, Λ; process=true)\n",
    "#obs = Observer([\"F\" => F])\n",
    "\n",
    "print(\"Part 3---------------------------------------------\")\n",
    "\n",
    "N = size(data, 2) # Number of qubits\n",
    "\n",
    "opt = Optimisers.ADAM() #optimizer\n",
    "#opt=Optimisers.Descent(0.01)\n",
    "\n",
    "# Run quantum state tomography\n",
    "Λ = tomography(data, U0; optimizer = opt, test_data = target,target=Λ1, batchsize=500,epochs=100) #observer=obs,\n",
    "#display(Λ)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational tensor network: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "16-element Vector{ComplexF64}:\n",
       "    0.04619703643647061 - 0.6164726597758794im\n",
       "   -0.49293715791112075 - 0.5777797980893581im\n",
       "      -0.55076066551705 + 0.5699259783582641im\n",
       "   0.050482928973565794 + 0.15761664641343726im\n",
       "     0.3320597997419309 - 0.7334602570113685im\n",
       "   -0.20918853973231027 - 0.20823046157166908im\n",
       "   -0.22597955672626108 + 0.11561929028525401im\n",
       "    0.10862808821071185 + 0.18191582991223038im\n",
       "   -0.12428496842281095 - 0.27262433138216025im\n",
       "   0.019348165385902637 + 0.22294901168193784im\n",
       " -0.0034558009363883646 + 0.236596618322161im\n",
       "   -0.17272778073670614 - 0.4203133796558753im\n",
       "     0.6046556346250295 + 0.530881710110966im\n",
       "    0.04514434870631548 - 0.27297869615628534im\n",
       "   -0.11715146035410286 - 0.2580195420968451im\n",
       "    0.22939523553546565 + 0.5305953286004398im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum circuit: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "16-element Vector{ComplexF64}:\n",
       "    0.08180867575003772 + 0.022237863339273342im\n",
       "      0.789712492678016 - 0.08388240789701462im\n",
       "   -0.16336210488290992 - 0.30726264264615455im\n",
       "   -0.30241868895141855 - 0.3867507805487037im\n",
       "     0.4192013751559086 + 0.8394372381604367im\n",
       "    -0.1379403316805653 - 0.2204475366495596im\n",
       "    0.08294744225997683 - 0.037346101907064305im\n",
       "    0.10235779066034822 - 0.1823144314747876im\n",
       " -0.0023252943484326325 + 0.26224992912741707im\n",
       "  -0.004144539115334855 + 0.3489834535958693im\n",
       "    0.10039652542826079 - 0.38172407698465627im\n",
       "    -0.5328899874552204 + 0.6079872265046382im\n",
       "   -0.06925076924603449 + 0.1971092258134826im\n",
       "   -0.14404965406521997 + 0.39891896183332853im\n",
       "    -0.7829531738666449 + 0.31909101504350623im\n",
       "    -0.1936462477886211 - 0.155344859842848im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE non normalized:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.64233604017714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Λ1,Λ - quantum circuit tensor network and variational tensor network\n",
    "\n",
    "#Variational vector format\n",
    "Λmat = PastaQ.array(Λ)\n",
    "Λvec = vec(Λmat)\n",
    "\n",
    "print(\"Variational tensor network:\")\n",
    "print(\" \")\n",
    "display(Λvec)\n",
    "\n",
    "#Random circuit vector format\n",
    "Λmat1 = PastaQ.array(Λ1)\n",
    "Λvec1 = vec(Λmat1)\n",
    "\n",
    "\n",
    "print(\"Quantum circuit:\")\n",
    "print(\" \")\n",
    "display(Λvec1)\n",
    "\n",
    "MSE=0\n",
    "for i in 1:size(Λvec, 1)\n",
    "    MSE=abs(Λvec[i]*Λvec[i]-Λvec1[i]*Λvec1[i]) + MSE\n",
    "end \n",
    "\n",
    "#MSE=MSE/size(Λvec, 1)\n",
    "\n",
    "print(\"MSE non normalized:\")\n",
    "display(MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 * 1 = 9\n",
      "9 * 2 = 18\n",
      "9 * 3 = 27\n",
      "9 * 4 = 36\n",
      "9 * 5 = 45\n",
      "9 * 6 = 54\n",
      "9 * 7 = 63\n",
      "9 * 8 = 72\n",
      "9 * 9 = 81\n",
      "9 * 10 = 90\n"
     ]
    }
   ],
   "source": [
    "for i in 1:10\n",
    "    println(\"9 * $i = \",9*i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = (dim=3|id=650|\"a\")\n",
      "hasinds(C, a, b, c, i, j) = true\n",
      "C = ITensor ord=5\n",
      "Dim 1: (dim=3|id=650|\"a\")\n",
      "Dim 2: (dim=2|id=684|\"b\")\n",
      "Dim 3: (dim=4|id=274|\"c\")\n",
      "Dim 4: (dim=2|id=592|\"i\")\n",
      "Dim 5: (dim=6|id=110|\"j\")\n",
      "NDTensors.Dense{Float64, Vector{Float64}}\n",
      " 3×2×4×2×6\n",
      "[:, :, 1, 1, 1] =\n",
      "  0.7480220297079663   1.145704070939422\n",
      " -0.826344480858588   -1.1465923533586044\n",
      "  0.3858421121494405   0.3027515922530699\n",
      "\n",
      "[:, :, 2, 1, 1] =\n",
      "  0.6576731256531949   4.055911860244057\n",
      " -2.6284339811853514   1.2600416120777944\n",
      "  1.1356087722707142  -3.8132520273545127\n",
      "\n",
      "[:, :, 3, 1, 1] =\n",
      " 0.3010359475553373  0.8536598538370233\n",
      " 0.5354077430400139  4.450542505996551\n",
      " 7.894038252344049   2.1339642612187477\n",
      "\n",
      "[:, :, 4, 1, 1] =\n",
      "  2.2378611592135766   0.46324611566220547\n",
      " -1.8307879443393842  -3.258738466660836\n",
      " -3.842097728015382    0.24755921640331735\n",
      "\n",
      "[:, :, 1, 2, 1] =\n",
      "  0.0860566330450529   -2.033552559987741\n",
      " -0.8433938621721965   -1.0229837240682216\n",
      "  0.41921310572563425  -0.7406398013092955\n",
      "\n",
      "[:, :, 2, 2, 1] =\n",
      " 1.3044262828264466   0.1915120885612881\n",
      " 0.5862671768067506  -0.7282442459848466\n",
      " 0.4149564602868671  -0.29439013459181457\n",
      "\n",
      "[:, :, 3, 2, 1] =\n",
      " 0.296209638088463    1.7727357376124344\n",
      " 0.6262237262330955  -0.7000113078216387\n",
      " 2.3842279819399588   0.1772660074749124\n",
      "\n",
      "[:, :, 4, 2, 1] =\n",
      " 1.2419249451285845   -1.098173888943827\n",
      " 0.7509821410894926   -0.4104737444294056\n",
      " 0.04986076783052082  -0.6004877283783311\n",
      "\n",
      "[:, :, 1, 1, 2] =\n",
      " -1.2481106542518645   0.34786279241969603\n",
      " -0.41862839814772973  1.6252218230910516\n",
      " -1.1095130504407695   1.7766760143659632\n",
      "\n",
      "[:, :, 2, 1, 2] =\n",
      " -0.5916796518385685  -1.8093495744029\n",
      "  0.4772219160539599   0.7660287994173469\n",
      " -1.2234253058425775   2.5901633814946705\n",
      "\n",
      "[:, :, 3, 1, 2] =\n",
      "  0.0215139525926062    0.006880026907139454\n",
      " -0.18658219799032863  -0.6159067922336604\n",
      " -3.839502171609734    -2.7889453631701215\n",
      "\n",
      "[:, :, 4, 1, 2] =\n",
      " -2.8066493364902008   0.6544202387541013\n",
      " -2.6225218806123376   2.394586964585275\n",
      "  2.0091063787549763  -0.9878456389833212\n",
      "\n",
      "[:, :, 1, 2, 2] =\n",
      " -2.3200204634957675   -0.9454241593886535\n",
      " -0.594057295393598     3.7349064218574544\n",
      "  0.38875867709783396  -0.7991117980507274\n",
      "\n",
      "[:, :, 2, 2, 2] =\n",
      " -0.2753184667864654   1.248614678896607\n",
      " -0.19494686356651755  0.765329196759033\n",
      "  1.6288286482708996   1.137369586940237\n",
      "\n",
      "[:, :, 3, 2, 2] =\n",
      " -1.3878287249677819   1.2158523148213067\n",
      "  1.2344707399551598   0.6742842103720426\n",
      "  4.251327313939737   -2.0123767449544037\n",
      "\n",
      "[:, :, 4, 2, 2] =\n",
      " -0.8422358949342595   0.05527896756041224\n",
      " -2.9962592394697336   1.1395610573728392\n",
      " -1.4534663564539403  -1.0471322476831817\n",
      "\n",
      "[:, :, 1, 1, 3] =\n",
      "  0.9885751789542335  -1.568573369129222\n",
      "  1.244811079911024    7.524510699589606\n",
      " -4.761228651347721   -3.3059104256112883\n",
      "\n",
      "[:, :, 2, 1, 3] =\n",
      " -5.995198802059605   -0.011748912703277454\n",
      "  2.3569199261413796   0.04180231287010131\n",
      "  5.611602478620399    1.3667640387387858\n",
      "\n",
      "[:, :, 3, 1, 3] =\n",
      " -1.7670321352069893   0.4458728638853164\n",
      "  0.32115676900652607  2.2932975707430923\n",
      " -2.049183455749313    2.7568203940109557\n",
      "\n",
      "[:, :, 4, 1, 3] =\n",
      "  2.850908684688916   0.5026355810234799\n",
      " -1.8071235746376018  5.106088715408945\n",
      "  2.01822826401403    3.506324840441895\n",
      "\n",
      "[:, :, 1, 2, 3] =\n",
      " -0.5302237200872055   1.7755256437750655\n",
      "  1.5520719263971987   0.2838202776708542\n",
      "  1.9104738070747918  -0.8314148406994225\n",
      "\n",
      "[:, :, 2, 2, 3] =\n",
      " -0.19044409780173668   0.31872056693661655\n",
      " -0.6577983114622552   -0.1652806377865393\n",
      " -0.2912480859864351   -0.30281317416012843\n",
      "\n",
      "[:, :, 3, 2, 3] =\n",
      " -0.9230733837352589   -2.507210153376742\n",
      " -0.3980594644294539   -0.927161683611439\n",
      " -0.42663780669320006   0.1425739729717269\n",
      "\n",
      "[:, :, 4, 2, 3] =\n",
      " -0.8312192659319351   0.45035993999462753\n",
      "  1.9247945243886562  -1.1410654398048854\n",
      " -1.6378445787356846   0.480637717336704\n",
      "\n",
      "[:, :, 1, 1, 4] =\n",
      "  1.888289792622767   -2.0717671833223923\n",
      " -1.4233941975098503   0.7804386079496874\n",
      " -4.236624597139118    0.5005076663031943\n",
      "\n",
      "[:, :, 2, 1, 4] =\n",
      " -1.7105496299593124  -0.44780563081592006\n",
      "  1.3062478584339798   0.23729766034343838\n",
      "  1.6659206959229953   0.0821871766030701\n",
      "\n",
      "[:, :, 3, 1, 4] =\n",
      "  1.1332448421151071   2.8674554731742017\n",
      "  0.16085686728353896  2.3498924944263764\n",
      " -1.0891848900147547   1.5792397592820007\n",
      "\n",
      "[:, :, 4, 1, 4] =\n",
      "  2.3375062020010318  -0.2201409828962175\n",
      " -2.455959020632346    2.4736538894463593\n",
      "  2.9042964470447874   0.9616580902817221\n",
      "\n",
      "[:, :, 1, 2, 4] =\n",
      "  0.5034519132410622   0.6209745810555092\n",
      "  1.418251941140315    4.808848937442629\n",
      " -1.9259317047148266  -2.3300100944957824\n",
      "\n",
      "[:, :, 2, 2, 4] =\n",
      " -3.8733744831340124    1.5924193983201334\n",
      "  0.12759053528532016   0.5251718645615908\n",
      "  3.7859650137638954   -0.5336130845466648\n",
      "\n",
      "[:, :, 3, 2, 4] =\n",
      " -1.5942067418982175   -0.962483152814828\n",
      "  0.13110855163106624   2.654024155841364\n",
      "  1.0261621487225867    2.452282822341207\n",
      "\n",
      "[:, :, 4, 2, 4] =\n",
      "  1.9169605362964297  0.8902820867356858\n",
      " -1.0119996166375969  1.6020135941427713\n",
      " -0.9856671178981794  2.6053190406510347\n",
      "\n",
      "[:, :, 1, 1, 5] =\n",
      "  0.17862797558371735   2.1074637462009487\n",
      " -0.6127579755910094   -1.8278204103830504\n",
      "  0.2300240288595358    2.2587999635668696\n",
      "\n",
      "[:, :, 2, 1, 5] =\n",
      "  0.8426698329678852   1.286039968497295\n",
      " -2.0301118266364977   1.3042425212926243\n",
      " -1.4986356430096688  -1.5007058795297774\n",
      "\n",
      "[:, :, 3, 1, 5] =\n",
      "  0.8027342191486149   -0.350548022587578\n",
      " -0.31661124956427744   2.255564301151636\n",
      "  1.598935061137845    -0.2120928936235064\n",
      "\n",
      "[:, :, 4, 1, 5] =\n",
      " -0.7940707508855996   0.9184103637936106\n",
      " -1.8816746927641455  -1.872611649884096\n",
      " -1.4010112232193104  -0.5799483936651917\n",
      "\n",
      "[:, :, 1, 2, 5] =\n",
      " -0.2691538094301691  -5.415158825864434\n",
      " -1.11234178896696    -0.09551769044305249\n",
      "  0.7307318064047723  -3.1949136540752825\n",
      "\n",
      "[:, :, 2, 2, 5] =\n",
      " 1.760918833551354   -0.4923110288513843\n",
      " 2.588422340028406   -2.2653988515331784\n",
      " 2.0519326585496405   0.7312607703219909\n",
      "\n",
      "[:, :, 3, 2, 5] =\n",
      " -0.24564910409155397   3.5964219105542945\n",
      "  1.5237033492019054   -3.00135572833491\n",
      "  3.6364772499660982    0.23875179434278032\n",
      "\n",
      "[:, :, 4, 2, 5] =\n",
      " 2.7526781009559644  -2.7151337160824376\n",
      " 2.562074104169735    0.7502940789789887\n",
      " 0.9478775094757774  -0.7924189072397172\n",
      "\n",
      "[:, :, 1, 1, 6] =\n",
      " -1.0521391500543062  -0.12199081983904092\n",
      " -1.3626887137998742  -2.055798258673923\n",
      "  1.5801909055501526   1.4858934644849335\n",
      "\n",
      "[:, :, 2, 1, 6] =\n",
      "  2.6031915503295093   0.7390098901332505\n",
      " -1.1378228471830603   0.4689237180820803\n",
      " -1.6419933572531877  -0.41194177089083406\n",
      "\n",
      "[:, :, 3, 1, 6] =\n",
      " 0.5917116256528063   1.1666267049090544\n",
      " 0.4949285272995213   0.01707030856555662\n",
      " 3.3136055388044663  -1.816944431692702\n",
      "\n",
      "[:, :, 4, 1, 6] =\n",
      " -1.0995412232726398  -0.27886106592682036\n",
      " -1.2086906679009712  -1.695155498900738\n",
      " -1.2179134940306728  -2.0524448185380884\n",
      "\n",
      "[:, :, 1, 2, 6] =\n",
      " 2.322163924961527   -0.13912559433201305\n",
      " 3.6128067269301076   0.05534215913630419\n",
      " 0.8774257258370285  -4.678392965595589\n",
      "\n",
      "[:, :, 2, 2, 6] =\n",
      " -2.2242783023685853  -1.3354059751583467\n",
      "  2.1696694059475687  -2.837717657880885\n",
      "  2.040348470405658   -0.7140335836566538\n",
      "\n",
      "[:, :, 3, 2, 6] =\n",
      " -1.1641331668149033  -3.4947387242435877\n",
      " -1.066765110681711   -3.378298436765304\n",
      " -4.836228552269773    4.56693628445699\n",
      "\n",
      "[:, :, 4, 2, 6] =\n",
      " 3.0589013810086834  -0.8279644460498237\n",
      " 8.16944146883185    -0.1339250331914432\n",
      " 0.5827331913862601   3.6920879276825915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=5 (dim=3|id=650|\"a\") (dim=2|id=684|\"b\") (dim=4|id=274|\"c\") (dim=2|id=592|\"i\") (dim=6|id=110|\"j\")\n",
       "NDTensors.Dense{Float64, Vector{Float64}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ITensors\n",
    "function main()\n",
    "    a = Index(3,\"a\")\n",
    "    @show a\n",
    "    b = Index(2,\"b\")\n",
    "    c = Index(4,\"c\")\n",
    "    d = Index(5,\"d\")\n",
    "    i = Index(2,\"i\")\n",
    "    j = Index(6,\"j\")\n",
    "    A = randomITensor(a,b,d,c)\n",
    "    B = randomITensor(i,d,j)\n",
    "    \n",
    "    C = A * B\n",
    "    @show hasinds(C,a,b,c,i,j)\n",
    "    @show C\n",
    "    return C\n",
    "end\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working version with tomography using variational tensor networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12345"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InexactError: Int64(24.3)",
     "output_type": "error",
     "traceback": [
      "InexactError: Int64(24.3)",
      "",
      "Stacktrace:",
      " [1] Int64",
      "   @ .\\float.jl:900 [inlined]",
      " [2] split_dataset(data::Matrix{Pair{String, Pair{String, Int64}}}; train_ratio::Float64, randomize::Bool)",
      "   @ PastaQ C:\\Users\\vladl\\.julia\\packages\\PastaQ\\D5CCg\\src\\utils.jl:135",
      " [3] top-level scope",
      "   @ In[14]:28"
     ]
    }
   ],
   "source": [
    "using PastaQ\n",
    "using Random\n",
    "using ITensors\n",
    "using Observers\n",
    "using Optimisers: Optimisers\n",
    "\n",
    "\n",
    "N = 3\n",
    "depth = 4\n",
    "nshots = 3\n",
    "\n",
    "gates = randomcircuit(N; depth=4)\n",
    "print(\"1\")\n",
    "\n",
    "Λ = runcircuit(gates; process=true)\n",
    "print(\"2\")\n",
    "\n",
    "preps = randompreparations(N,nshots)\n",
    "print(\"3\")\n",
    "\n",
    "bases = randombases(N,nshots)\n",
    "print(\"4\")\n",
    "\n",
    "data = getsamples(Λ, preps, bases, nshots)\n",
    "\n",
    "print(\"5\")\n",
    "\n",
    "data, target = split_dataset(data; train_ratio=0.9)\n",
    "print(\"6\")\n",
    "\n",
    "\n",
    "χ = maxlinkdim(ρ) #\n",
    "U0 = randomprocess(ρ; χ=χ) #definition of the variational circuit\n",
    "display(U0)\n",
    "print(\"7\")\n",
    "\n",
    "N = size(data, 2) # Number of qubits\n",
    "\n",
    "opt = Optimisers.ADAM() #optimizer\n",
    "\n",
    "# Set parameters\n",
    "##N = length(Û)     # Number of qubits\n",
    "##χ = maxlinkdim(Û) # Bond dimension of variational MPS\n",
    "##U0 = randomprocess(Û; χ=χ)\n",
    "\n",
    "\n",
    "# Run quantum state tomography\n",
    "Λ = tomography(data, U0; optimizer = opt, target = target)\n",
    "display(Λ)\n",
    "\n",
    "for j in 1:N\n",
    "    s = firstind(ρ; tags=\"Output,n=$(j)\", plev=0)\n",
    "    ρ = ρ * δ(s, s')\n",
    "  end\n",
    "\n",
    "ρmat = PastaQ.array(ρ)\n",
    "display(ρmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random circuit of depth 4 on 4 qubits:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector}:\n",
       " Any[(\"CX\", (1, 2)), (\"CX\", (3, 4)), (\"Rn\", 1, (θ = 1.0240860966391014, ϕ = 3.449790032588226, λ = 0.6867102289516064)), (\"Rn\", 2, (θ = 2.8093548677424836, ϕ = 2.218665895883152, λ = 1.2385897659119816)), (\"Rn\", 3, (θ = 2.9943293270335696, ϕ = 4.998568891921718, λ = 1.5527317508606786)), (\"Rn\", 4, (θ = 2.351215134597933, ϕ = 3.633138470776425, λ = 2.286875252144381))]\n",
       " Any[(\"CX\", (2, 3)), (\"Rn\", 1, (θ = 0.02339860135090042, ϕ = 1.2527202123030283, λ = 1.3799229760638079)), (\"Rn\", 2, (θ = 2.1442395975985904, ϕ = 6.011380704980616, λ = 2.035297500617958)), (\"Rn\", 3, (θ = 3.1311163576685583, ϕ = 4.7073251097507764, λ = 0.34583990610826215)), (\"Rn\", 4, (θ = 1.5437258380134744, ϕ = 3.550913017731251, λ = 0.7973732429466119))]\n",
       " Any[(\"CX\", (1, 2)), (\"CX\", (3, 4)), (\"Rn\", 1, (θ = 1.9691311440778374, ϕ = 1.4709222894013594, λ = 0.3920454955798837)), (\"Rn\", 2, (θ = 1.915978397587573, ϕ = 4.227282390786751, λ = 2.393628962683993)), (\"Rn\", 3, (θ = 1.8499961361059682, ϕ = 2.2987281223964726, λ = 0.4116292390152326)), (\"Rn\", 4, (θ = 2.9733705024948724, ϕ = 3.608580884268896, λ = 2.128899971420636))]\n",
       " Any[(\"CX\", (2, 3)), (\"Rn\", 1, (θ = 1.795691564518111, ϕ = 0.4568889955885932, λ = 2.202620358166489)), (\"Rn\", 2, (θ = 0.2991346706817105, ϕ = 5.312524925050449, λ = 1.0964008943380803)), (\"Rn\", 3, (θ = 2.4137119207736015, ϕ = 1.690552126010903, λ = 1.6953014741642007)), (\"Rn\", 4, (θ = 0.9233293544779918, ϕ = 1.5217543695598081, λ = 3.07269664603405))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying random circuit to compute |ψ⟩ = U|0,0,…,0⟩...\n",
      "maxlinkdim(ψ) = 4\n",
      "\n",
      "Approximating random circuit as an MPO U...\n",
      "maxlinkdim(U) = 4\n",
      "\n",
      "Running the circuit with amplitude damping to compute the state ρ = ε(|0,0,…⟩⟨0,0,…|)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNoise model not defined for 2-qubit gates! Applying tensor-product noise instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ PastaQ C:\\Users\\vladl\\.julia\\packages\\PastaQ\\D5CCg\\src\\circuits\\noise.jl:177\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNoise model not defined for 2-qubit gates! Applying tensor-product noise instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ PastaQ C:\\Users\\vladl\\.julia\\packages\\PastaQ\\D5CCg\\src\\circuits\\noise.jl:177\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNoise model not defined for 2-qubit gates! Applying tensor-product noise instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ PastaQ C:\\Users\\vladl\\.julia\\packages\\PastaQ\\D5CCg\\src\\circuits\\noise.jl:177\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNoise model not defined for 2-qubit gates! Applying tensor-product noise instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ PastaQ C:\\Users\\vladl\\.julia\\packages\\PastaQ\\D5CCg\\src\\circuits\\noise.jl:177\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNoise model not defined for 2-qubit gates! Applying tensor-product noise instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ PastaQ C:\\Users\\vladl\\.julia\\packages\\PastaQ\\D5CCg\\src\\circuits\\noise.jl:177\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using PastaQ\n",
    "using ITensors\n",
    "using Random\n",
    "\n",
    "Random.seed!(1234)\n",
    "\n",
    "N = 4     # Number of qubits\n",
    "depth = 4 # Depth of the quantum circuit\n",
    "\n",
    "# Generate random quantum circuit built out of\n",
    "# layers of single-qubit random rotations + `CX` \n",
    "# gates, alternating between even and of odd layers.\n",
    "println(\"Random circuit of depth $depth on $N qubits:\")\n",
    "circuit = randomcircuit(N, depth=depth; twoqubitgates=\"CX\", onequbitgates=\"Rn\")\n",
    "display(circuit)\n",
    "println()\n",
    "\n",
    "# 1. Unitary quantum circuit\n",
    "# Returns the MPS at the output of the quantum circuit:\n",
    "# `|ψ⟩ = Û|0,0,…,0⟩`\n",
    "# where `Û` is the unitary circuit.\n",
    "println(\"Applying random circuit to compute |ψ⟩ = U|0,0,…,0⟩...\")\n",
    "ψ = runcircuit(circuit)\n",
    "@show maxlinkdim(ψ)\n",
    "println()\n",
    "\n",
    "# A representation of the unitary operation as a MPO\n",
    "# is obtained using the flag `process=true`:\n",
    "println(\"Approximating random circuit as an MPO U...\")\n",
    "U = runcircuit(circuit; process=true)\n",
    "@show maxlinkdim(U)\n",
    "println()\n",
    "\n",
    "# 2. Quantum circuit with noise\n",
    "# Apply a noise model `noise` (specified by appropriate \n",
    "# parameters) to each quantum gate in `gates`.\n",
    "# Returns a mixed density operator as MPO:\n",
    "# `ρ = ε(|0,0,…⟩⟨0,0,…|)`\n",
    "# where `ε` is the quantum channel.\n",
    "# Here, the noise is a single-qubit amplitude damping \n",
    "# channel with decay rate `γ=0.01`..\n",
    "println(\n",
    "  \"Running the circuit with amplitude damping to compute the state ρ = ε(|0,0,…⟩⟨0,0,…|)...\"\n",
    ")\n",
    "ρ = runcircuit(circuit; noise=(\"amplitude_damping\", (γ=0.01,)))\n",
    "@show maxlinkdim(ρ)\n",
    "println()\n",
    "\n",
    "# A representation of the quantum channel as a MPO\n",
    "# is obtained using the flag `process=true`, which \n",
    "# returns the Choi matrix `Λ` of the channel:`:\n",
    "println(\n",
    "  \"Running the circuit with amplitude damping to compute the Choi matrix Λ of the quantum channel...\",\n",
    ")\n",
    "Λ = runcircuit(circuit; process=true, noise=(\"amplitude_damping\", (γ=0.01,)))\n",
    "@show maxlinkdim(Λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PastaQ\n",
    "using Random\n",
    "using ITensors\n",
    "using Observers\n",
    "using Optimisers: Optimisers\n",
    "\n",
    "\n",
    "N = 3\n",
    "depth = 4\n",
    "nshots = 100\n",
    "circuit = randomcircuit(N,depth=depth)\n",
    "ρ = runcircuit(circuit) #density matrix\n",
    "\n",
    "bases= randombases(N, nshots) #basis of dimension 3 with 100 shots\n",
    "print(\"bases:\")\n",
    "display(bases)\n",
    "\n",
    "\n",
    "data=getsamples(ρ,bases) #sample density matrix in the basis for training and testing data\n",
    "target=getsamples(ρ,bases)\n",
    "\n",
    "χ = maxlinkdim(ρ) #\n",
    "U0 = randomstate(ρ; χ=χ)\n",
    "print(\"Random state:\")\n",
    "display(U0)\n",
    "#display(U)\n",
    "\n",
    "#print(circuit)\n",
    "# Generate samples\n",
    "#print(bases)\n",
    "#data,Û= getsamples(ρ, bases,nshots)\n",
    "##data = getsamples(ρ, nshots)\n",
    "#target = getsamples(ρ, nshots)\n",
    "\n",
    "#display(data)\n",
    "\n",
    "#writesamples(data, U, \"data/qpt_circuit.h5\")\n",
    "\n",
    "# Load target state and measurements. Each samples is built out\n",
    "# of an input state (`first.(data)`) to the quantum channel, and the\n",
    "# measurement output (`last.(data)`) after a local basis rotation.\n",
    "#data, Û = readsamples(\"data/qpt_circuit.h5\")\n",
    "\n",
    "# Split data into a train and test dataset\n",
    "\n",
    "#data, target = split_dataset(data; train_ratio=0.9)\n",
    "\n",
    "display(data)\n",
    "display(target)\n",
    "\n",
    "# Load the training data, as well as the target quantum state from file.\n",
    "#data, target = loadsamples(\"PATH_TO_DATAFILE.h5\")\n",
    "N = size(data, 2) # Number of qubits\n",
    "print(\"N:\")\n",
    "display(N)\n",
    "# 1. Reconstruction with a variational MPO:\n",
    "#\n",
    "\n",
    "# Initialize stochastic gradient descent with learning rate η = 0.01\n",
    "opt = Optimisers.ADAM()\n",
    "\n",
    "# Run quantum state tomography\n",
    "#U = tomography(data, U0; optimizer = opt, target = target)\n",
    "\n",
    "# 2. Reconstruction with a variational density matrix:\n",
    "#\n",
    "# Initialize a variational LPDO with bond dimension χ = 10 and Kraus dimension ξ = 2.\n",
    "Λ0 = randomprocess(N; mixed = true, χ = 10, ξ = 3)\n",
    "\n",
    "# Set parameters\n",
    "##N = length(Û)     # Number of qubits\n",
    "##χ = maxlinkdim(Û) # Bond dimension of variational MPS\n",
    "##U0 = randomprocess(Û; χ=χ)\n",
    "\n",
    "display(Λ0)\n",
    "\n",
    "# Run quantum state tomography\n",
    "Λ = tomography(data, U0; optimizer = opt, target = target)\n",
    "display(Λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "  χ = 4\n",
    "  nsamples = 10\n",
    "  trace_preserving_regularizer = 0.1\n",
    "  Random.seed!(1234)\n",
    "  data = randompreparations(N, nsamples)\n",
    "  data_out = PastaQ.convertdatapoints(randompreparations(N, nsamples))\n",
    "  data = data_in .=> data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test full tomography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ITensors\n",
    "using PastaQ\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "\n",
    "using SCS\n",
    "using Convex\n",
    "\n",
    "@testset \" counts and frequencies\" begin\n",
    "  N = 3\n",
    "  d = 1 << N\n",
    "  gates = randomcircuit(N; depth=4)\n",
    "  ψ = runcircuit(N, gates)\n",
    "\n",
    "  bases = fullbases(N)\n",
    "  samples = getsamples(ψ, bases, 100)\n",
    "\n",
    "  C = PastaQ.measurement_counts(samples)\n",
    "  @test length(keys(C)) == 3^N\n",
    "  probs1 = PastaQ.empirical_probabilities(samples)\n",
    "  @test length(keys(probs1)) == 3^N\n",
    "  probs2 = PastaQ.empirical_probabilities(C)\n",
    "  @test length(keys(probs2)) == 3^N\n",
    "  @test probs1 == probs2\n",
    "\n",
    "  for (basis, counts_in_basis) in C\n",
    "    tot_counts = sum(values(counts_in_basis))\n",
    "    for (proj, counts) in counts_in_basis\n",
    "      freq = counts / tot_counts\n",
    "      @test freq ≈ probs1[basis][proj]\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "@testset \"POVM matrix\" begin\n",
    "  N = 3\n",
    "  d = 1 << N\n",
    "  gates = randomcircuit(N, ; depth=4)\n",
    "  ψ = runcircuit(N, gates)\n",
    "\n",
    "  bases = fullbases(N)\n",
    "  samples = getsamples(ψ, bases, 100)\n",
    "\n",
    "  ρ = outer(ψ', ψ)\n",
    "  ρmat = PastaQ.array(ρ)\n",
    "  #ρ = projector(toarray(ψ))\n",
    "  ρ_vec = vec(ρmat)\n",
    "\n",
    "  probs = PastaQ.empirical_probabilities(samples)\n",
    "  A = PastaQ.design_matrix(probs; return_probs=false)\n",
    "  real_probs = A * ρ_vec\n",
    "  ρ̂_vec = pinv(A) * real_probs\n",
    "  ρ̂ = reshape(ρ̂_vec, (d, d))\n",
    "  @test ρmat ≈ ρ̂\n",
    "end\n",
    "\n",
    "@testset \"make PSD\" begin\n",
    "  ρ = zeros(5, 5)\n",
    "  ρ[1, 1] = 3 / 5\n",
    "  ρ[2, 2] = 1 / 2\n",
    "  ρ[3, 3] = 7 / 20\n",
    "  ρ[4, 4] = 1 / 10\n",
    "  ρ[5, 5] = -11 / 20\n",
    "\n",
    "  ρ̂ = PastaQ.make_PSD(ρ)\n",
    "  λ = reverse(first(eigen(ρ̂)))\n",
    "  @test λ[1] ≈ 9 / 20\n",
    "  @test λ[2] ≈ 7 / 20\n",
    "  @test λ[3] ≈ 1 / 5\n",
    "  @test λ[4] ≈ 0.0\n",
    "  @test λ[5] ≈ 0.0\n",
    "end\n",
    "\n",
    "@testset \"PSD constraint in QST\" begin\n",
    "  N = 2\n",
    "  d = 1 << N\n",
    "  gates = randomcircuit(N; depth=4)\n",
    "  ψ = runcircuit(N, gates)\n",
    "\n",
    "  bases = fullbases(N)\n",
    "  samples = getsamples(ψ, bases, 100)\n",
    "\n",
    "  ϱ = PastaQ.array(outer(ψ', ψ))\n",
    "\n",
    "  ρ = PastaQ.array(tomography(samples; method=\"LI\"))\n",
    "  λ = first(eigen(ρ))\n",
    "  @test all(λ .≥ -1e-4)\n",
    "\n",
    "  ρ = PastaQ.array(tomography(samples; method=\"LS\"))\n",
    "  λ = first(eigen(ρ))\n",
    "  @test all(real(λ) .≥ -1e-3)\n",
    "\n",
    "  ρ = PastaQ.array(tomography(samples; method=\"MLE\"))\n",
    "  λ = first(eigen(ρ))\n",
    "  @test all(real(λ) .≥ -1e-2)\n",
    "end\n",
    "\n",
    "@testset \"arbitrary trace in QST\" begin\n",
    "  N = 2\n",
    "  d = 1 << N\n",
    "  gates = randomcircuit(N; depth=4)\n",
    "  ψ = runcircuit(N, gates)\n",
    "\n",
    "  bases = fullbases(N)\n",
    "  samples = getsamples(ψ, bases, 100)\n",
    "\n",
    "  ϱ = PastaQ.array(outer(ψ', ψ))\n",
    "\n",
    "  ρ = PastaQ.array(tomography(samples; method=\"LI\", trρ=2.0))\n",
    "  @test tr(ρ) ≈ 2.0\n",
    "  ρ = PastaQ.array(tomography(samples; method=\"LS\", trρ=2.0))\n",
    "  @test tr(ρ) ≈ 2.0 atol = 1e-4\n",
    "  ρ = PastaQ.array(tomography(samples; method=\"MLE\", trρ=2.0))\n",
    "  @test tr(ρ) ≈ 2.0 atol = 1e-4\n",
    "end\n",
    "\n",
    "@testset \"Choi POVM matrix\" begin\n",
    "  N = 2\n",
    "  d = 2^(2 * N)\n",
    "  nshots = 3\n",
    "  gates = randomcircuit(N; depth=2)\n",
    "\n",
    "  Λ = runcircuit(gates; process=true, noise=(\"DEP\", (p=0.001,)))\n",
    "  preps = fullpreparations(N)\n",
    "  bases = fullbases(N)\n",
    "  data = getsamples(Λ, preps, bases, nshots)\n",
    "\n",
    "  Λmat = PastaQ.array(Λ)\n",
    "  Λvec = vec(Λmat)\n",
    "\n",
    "  probs = PastaQ.empirical_probabilities(data)\n",
    "  A = PastaQ.design_matrix(probs; return_probs=false, process=true)\n",
    "  real_probs = A * Λvec\n",
    "  Λ̂vec = pinv(A) * real_probs\n",
    "  Λ̂ = reshape(Λ̂vec, (d, d))\n",
    "  @test Λmat ≈ Λ̂\n",
    "end\n",
    "\n",
    "@testset \"PSD constraint in QPT\" begin\n",
    "  N = 2\n",
    "  d = 1 << N\n",
    "  nshots = 3\n",
    "  gates = randomcircuit(N; depth=4)\n",
    "  Λ = runcircuit(gates; process=true, noise=(\"DEP\", (p=0.001,)))\n",
    "  preps = fullpreparations(N)\n",
    "  bases = fullbases(N)\n",
    "  data = getsamples(Λ, preps, bases, nshots)\n",
    "\n",
    "  ρ = PastaQ.array(tomography(data; method=\"LI\"))\n",
    "  λ = first(eigen(ρ))\n",
    "  @test all(λ .≥ -1e-4)\n",
    "\n",
    "  ρ = PastaQ.array(tomography(data; method=\"LS\"))\n",
    "  λ = first(eigen(ρ))\n",
    "  @test all(real(λ) .≥ -1e-4)\n",
    "end\n",
    "\n",
    "@testset \"Trace preserving condition in QPT\" begin\n",
    "  Random.seed!(1234)\n",
    "  N = 2\n",
    "  d = 1 << N\n",
    "  nshots = 3\n",
    "  gates = randomcircuit(N; depth=4)\n",
    "  Λ = runcircuit(gates; process=true, noise=(\"DEP\", (p=0.001,)))\n",
    "  preps = fullpreparations(N)\n",
    "  bases = fullbases(N)\n",
    "  data = getsamples(Λ, preps, bases, nshots)\n",
    "\n",
    "  ρ = tomography(data; method=\"LS\")\n",
    "  for j in 1:N\n",
    "    s = firstind(ρ; tags=\"Output,n=$(j)\", plev=0)\n",
    "    ρ = ρ * δ(s, s')\n",
    "  end\n",
    "\n",
    "  ρmat = PastaQ.array(ρ)\n",
    "  @test ρmat ≈ Matrix{Float64}(I, d, d) atol = 1e-5\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing get samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PastaQ\n",
    "using Random\n",
    "using ITensors\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "\n",
    "#\n",
    "# Helper functions for tests\n",
    "#\n",
    "\n",
    "function state_to_int(state::Array)\n",
    "  index = 0\n",
    "  for j in 1:length(state)\n",
    "    index += 2^(j - 1) * state[length(state) + 1 - j]\n",
    "  end\n",
    "  return index\n",
    "end\n",
    "\n",
    "function empiricalprobability(samples::Matrix)\n",
    "  prob = zeros((1 << size(samples)[2]))\n",
    "  for n in 1:size(samples)[1]\n",
    "    sample = samples[n, :]\n",
    "    index = state_to_int(sample)\n",
    "    prob[index + 1] += 1\n",
    "  end\n",
    "  prob = prob / size(samples)[1]\n",
    "  return prob\n",
    "end\n",
    "\n",
    "@testset \"generation of preparation states\" begin\n",
    "  N = 4\n",
    "  nstates = 100\n",
    "  states = PastaQ.randompreparations(N, nstates)\n",
    "  @test size(states)[1] == nstates\n",
    "  @test size(states)[2] == N\n",
    "end\n",
    "\n",
    "@testset \"generation of measurement bases\" begin\n",
    "  N = 4\n",
    "  nbases = 100\n",
    "  bases = randombases(N, nbases)\n",
    "  @test size(bases)[1] == nbases\n",
    "  @test size(bases)[2] == N\n",
    "\n",
    "  bases = fullbases(N)\n",
    "  @test bases isa Matrix{String}\n",
    "  @test size(bases) == (3^N, N)\n",
    "end\n",
    "\n",
    "@testset \"measurements\" begin\n",
    "  Random.seed!(1234)\n",
    "  N = 3\n",
    "  depth = 4\n",
    "  ψ0 = productstate(N)\n",
    "  gates = randomcircuit(N; depth=depth)\n",
    "  ψ = runcircuit(ψ0, gates)\n",
    "  ψ_vec = PastaQ.array(ψ)\n",
    "  probs = abs2.(ψ_vec)\n",
    "\n",
    "  nshots = 50000\n",
    "  samples = PastaQ.getsamples(ψ, nshots)\n",
    "  @test size(samples)[1] == nshots\n",
    "  @test size(samples)[2] == N\n",
    "  data_prob = empiricalprobability(samples)\n",
    "  @test probs ≈ data_prob atol = 1e-2\n",
    "\n",
    "  ρ = runcircuit(N, gates; noise=(\"depolarizing\", (p=0.01,)))\n",
    "  ρ_mat = PastaQ.array(ρ)\n",
    "  probs = real(diag(ρ_mat))\n",
    "\n",
    "  samples = PastaQ.getsamples(ρ, nshots)\n",
    "  @test size(samples)[1] == nshots\n",
    "  @test size(samples)[2] == N\n",
    "  data_prob = empiricalprobability(samples)\n",
    "  @test probs ≈ data_prob atol = 1e-2\n",
    "end\n",
    "\n",
    "@testset \"basis rotations\" begin\n",
    "  s = siteinds(\"Qubit\", 1)\n",
    "  #ϕ = qubits(1)\n",
    "  ψ0 = state(\"X+\", s[1])\n",
    "  gates = [(\"basisX\", 1, (dag=true,))]\n",
    "  ψ = runcircuit(ψ0, gates)\n",
    "  @test PastaQ.array(ψ) ≈ array(state(\"Z+\", s[1]))\n",
    "  ψ0 = state(\"X-\", s[1])\n",
    "  gates = [(\"basisX\", 1, (dag=true,))]\n",
    "  ψ = runcircuit(ψ0, gates)\n",
    "  @test PastaQ.array(ψ) ≈ array(state(\"Z-\", s[1]))\n",
    "\n",
    "  ψ0 = state(\"Y+\", s[1])\n",
    "  gates = [(\"basisY\", 1, (dag=true,))]\n",
    "  ψ = runcircuit(ψ0, gates)\n",
    "  @test PastaQ.array(ψ) ≈ array(state(\"Z+\", s[1]))\n",
    "  ψ0 = state(\"Y-\", s[1])\n",
    "  gates = [(\"basisY\", 1, (dag=true,))]\n",
    "  ψ = runcircuit(ψ0, gates)\n",
    "  @test PastaQ.array(ψ) ≈ array(state(\"Z-\", s[1]))\n",
    "end\n",
    "\n",
    "@testset \"project unitary MPO\" begin\n",
    "  N = 4\n",
    "  ntrial = 100\n",
    "  gates = randomcircuit(N; depth=4, layered=false)\n",
    "\n",
    "  U = runcircuit(N, gates; process=true)\n",
    "\n",
    "  bases = randombases(N, ntrial)\n",
    "  preps = randompreparations(N, ntrial)\n",
    "\n",
    "  for n in 1:ntrial\n",
    "    mgates = PastaQ.measurementgates(bases[n, :])\n",
    "    ψ_in = productstate(N, preps[n, :])\n",
    "    ψ_out = runcircuit(ψ_in, gates)\n",
    "\n",
    "    Ψ_out = PastaQ.projectchannel(U, preps[n, :])\n",
    "    @test PastaQ.array(ψ_out) ≈ PastaQ.array(Ψ_out)\n",
    "\n",
    "    ψ_m = runcircuit(ψ_out, mgates)\n",
    "    Ψ_m = runcircuit(Ψ_out, mgates)\n",
    "    @test PastaQ.array(ψ_m) ≈ PastaQ.array(Ψ_m)\n",
    "  end\n",
    "end\n",
    "\n",
    "@testset \"project unitary ITensor\" begin\n",
    "  N = 4\n",
    "  ntrial = 100\n",
    "  gates = randomcircuit(N; depth=4, layered=false)\n",
    "\n",
    "  U = runcircuit(N, gates; process=true, full_representation=true)\n",
    "  bases = randombases(N, ntrial)\n",
    "  preps = randompreparations(N, ntrial)\n",
    "\n",
    "  for n in 1:ntrial\n",
    "    mgates = PastaQ.measurementgates(bases[n, :])\n",
    "    ψ_in = productstate(N, preps[n, :])\n",
    "    ψ_out = runcircuit(ψ_in, gates)\n",
    "\n",
    "    Ψ_out = PastaQ.projectchannel(U, preps[n, :])\n",
    "    @test PastaQ.array(ψ_out) ≈ PastaQ.array(Ψ_out)\n",
    "\n",
    "    ψ_m = runcircuit(ψ_out, mgates)\n",
    "    Ψ_m = runcircuit(Ψ_out, mgates)\n",
    "    @test PastaQ.array(ψ_m) ≈ PastaQ.array(Ψ_m)\n",
    "  end\n",
    "end\n",
    "\n",
    "@testset \"project Choi MPO\" begin\n",
    "  N = 4\n",
    "  ntrial = 100\n",
    "  gates = randomcircuit(N; depth=4, layered=false)\n",
    "\n",
    "  Λ = runcircuit(N, gates; process=true, noise=(\"depolarizing\", (p=0.1,)))\n",
    "\n",
    "  bases = randombases(N, ntrial)\n",
    "  preps = PastaQ.randompreparations(N, ntrial)\n",
    "  for n in 1:ntrial\n",
    "    mgates = PastaQ.measurementgates(bases[n, :])\n",
    "    ψ_in = productstate(N, preps[n, :])\n",
    "    ρ_out = runcircuit(ψ_in, gates; noise=(\"depolarizing\", (p=0.1,)))\n",
    "\n",
    "    Λ_out = PastaQ.projectchannel(Λ, preps[n, :])\n",
    "    @test PastaQ.array(ρ_out) ≈ PastaQ.array(Λ_out) atol = 1e-6\n",
    "\n",
    "    ρ_m = runcircuit(ρ_out, mgates)\n",
    "    Λ_m = runcircuit(Λ_out, mgates)\n",
    "    @test PastaQ.array(ρ_m) ≈ PastaQ.array(Λ_m) atol = 1e-6\n",
    "  end\n",
    "end\n",
    "\n",
    "@testset \"project Choi ITensor\" begin\n",
    "  N = 4\n",
    "  ntrial = 100\n",
    "  gates = randomcircuit(N; depth=4, layered=false)\n",
    "\n",
    "  @disable_warn_order begin\n",
    "    Λ = runcircuit(\n",
    "      N, gates; process=true, noise=(\"depolarizing\", (p=0.1,)), full_representation=true\n",
    "    )\n",
    "\n",
    "    bases = randombases(N, ntrial)\n",
    "    preps = PastaQ.randompreparations(N, ntrial)\n",
    "    for n in 1:ntrial\n",
    "      mgates = PastaQ.measurementgates(bases[n, :])\n",
    "      ψ_in = productstate(N, preps[n, :])\n",
    "      ρ_out = runcircuit(ψ_in, gates; noise=(\"depolarizing\", (p=0.1,)))\n",
    "\n",
    "      Λ_out = PastaQ.projectchannel(Λ, preps[n, :])\n",
    "      @test PastaQ.array(ρ_out) ≈ PastaQ.array(Λ_out) atol = 1e-6\n",
    "\n",
    "      ρ_m = runcircuit(ρ_out, mgates)\n",
    "      Λ_m = runcircuit(Λ_out, mgates)\n",
    "      @test PastaQ.array(ρ_m) ≈ PastaQ.array(Λ_m) atol = 1e-6\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "@testset \"getsamples: states\" begin\n",
    "  N = 3\n",
    "  circuit = randomcircuit(N; depth=3)\n",
    "\n",
    "  # quantum states\n",
    "  ψ = runcircuit(N, circuit)\n",
    "  ρ = runcircuit(N, circuit; noise=(\"depolarizing\", (p=0.1,)))\n",
    "\n",
    "  nbases = 11\n",
    "  bases = randombases(N, nbases)\n",
    "  data = getsamples(ψ, bases)\n",
    "  @test size(data) == (nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(ψ, bases, nshots)\n",
    "  @test size(data) == (nbases * nshots, N)\n",
    "  for b in 1:nbases\n",
    "    for k in 1:nshots\n",
    "      @test first.(data[(b - 1) * nshots + k, :]) == bases[b, :]\n",
    "    end\n",
    "  end\n",
    "\n",
    "  data = getsamples(ρ, bases)\n",
    "  @test size(data) == (nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(ρ, bases, nshots)\n",
    "  @test size(data) == (nbases * nshots, N)\n",
    "  for b in 1:nbases\n",
    "    for k in 1:nshots\n",
    "      @test first.(data[(b - 1) * nshots + k, :]) == bases[b, :]\n",
    "    end\n",
    "  end\n",
    "\n",
    "  # ITensors quantum states\n",
    "  ψ = runcircuit(N, circuit; full_representation=true)\n",
    "  ρ = runcircuit(N, circuit; noise=(\"depolarizing\", (p=0.1,)), full_representation=true)\n",
    "\n",
    "  nbases = 11\n",
    "  bases = randombases(N, nbases)\n",
    "  data = getsamples(ψ, bases)\n",
    "  @test size(data) == (nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(ψ, bases, nshots)\n",
    "  @test size(data) == (nbases * nshots, N)\n",
    "  for b in 1:nbases\n",
    "    for k in 1:nshots\n",
    "      @test first.(data[(b - 1) * nshots + k, :]) == bases[b, :]\n",
    "    end\n",
    "  end\n",
    "\n",
    "  data = getsamples(ρ, bases)\n",
    "  @test size(data) == (nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(ρ, bases, nshots)\n",
    "  @test size(data) == (nbases * nshots, N)\n",
    "  for b in 1:nbases\n",
    "    for k in 1:nshots\n",
    "      @test first.(data[(b - 1) * nshots + k, :]) == bases[b, :]\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "@testset \"getsamples: channels\" begin\n",
    "  N = 3\n",
    "  circuit = randomcircuit(N; depth=3)\n",
    "\n",
    "  # quantum processes\n",
    "  U = runcircuit(N, circuit; process=true)\n",
    "  Λ = runcircuit(N, circuit; noise=(\"depolarizing\", (p=0.1,)), process=true)\n",
    "\n",
    "  npreps = 5\n",
    "  nbases = 7\n",
    "  preps = randompreparations(N, npreps)\n",
    "  bases = randombases(N, nbases)\n",
    "\n",
    "  data = getsamples(U, preps, bases)\n",
    "  @test size(data) == (npreps * nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(U, preps, bases, nshots)\n",
    "  @test size(data) == (npreps * nbases * nshots, N)\n",
    "\n",
    "  for p in 1:npreps\n",
    "    for b in 1:nbases\n",
    "      for k in 1:nshots\n",
    "        pdata = first.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :])\n",
    "        bdata = first.(last.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :]))\n",
    "        @test pdata == preps[p, :]\n",
    "        @test bdata == bases[b, :]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "\n",
    "  npreps = 5\n",
    "  nbases = 5\n",
    "  preps = randompreparations(N, npreps)\n",
    "  bases = randombases(N, nbases)\n",
    "\n",
    "  data = getsamples(U, preps .=> bases)\n",
    "  @test size(data) == (npreps, N)\n",
    "\n",
    "  data = getsamples(Λ, preps, bases)\n",
    "  @test size(data) == (npreps * nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(Λ, preps, bases, nshots)\n",
    "  @test size(data) == (npreps * nbases * nshots, N)\n",
    "\n",
    "  for p in 1:npreps\n",
    "    for b in 1:nbases\n",
    "      for k in 1:nshots\n",
    "        pdata = first.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :])\n",
    "        bdata = first.(last.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :]))\n",
    "        @test pdata == preps[p, :]\n",
    "        @test bdata == bases[b, :]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "\n",
    "  npreps = 5\n",
    "  nbases = 5\n",
    "  preps = randompreparations(N, npreps)\n",
    "  bases = randombases(N, nbases)\n",
    "\n",
    "  data = getsamples(Λ, preps .=> bases)\n",
    "  @test size(data) == (npreps, N)\n",
    "\n",
    "  # full representation\n",
    "  U = runcircuit(N, circuit; process=true, full_representation=true)\n",
    "  Λ = runcircuit(\n",
    "    N, circuit; noise=(\"depolarizing\", (p=0.1,)), process=true, full_representation=true\n",
    "  )\n",
    "\n",
    "  npreps = 5\n",
    "  nbases = 7\n",
    "  preps = randompreparations(N, npreps)\n",
    "  bases = randombases(N, nbases)\n",
    "\n",
    "  data = getsamples(U, preps, bases)\n",
    "  @test size(data) == (npreps * nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(U, preps, bases, nshots)\n",
    "  @test size(data) == (npreps * nbases * nshots, N)\n",
    "\n",
    "  for p in 1:npreps\n",
    "    for b in 1:nbases\n",
    "      for k in 1:nshots\n",
    "        pdata = first.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :])\n",
    "        bdata = first.(last.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :]))\n",
    "        @test pdata == preps[p, :]\n",
    "        @test bdata == bases[b, :]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "\n",
    "  data = getsamples(Λ, preps, bases)\n",
    "  @test size(data) == (npreps * nbases, N)\n",
    "  nshots = 3\n",
    "  data = getsamples(Λ, preps, bases, nshots)\n",
    "  @test size(data) == (npreps * nbases * nshots, N)\n",
    "\n",
    "  for p in 1:npreps\n",
    "    for b in 1:nbases\n",
    "      for k in 1:nshots\n",
    "        pdata = first.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :])\n",
    "        bdata = first.(last.(data[(p - 1) * nbases * nshots + (b - 1) * nshots + k, :]))\n",
    "        @test pdata == preps[p, :]\n",
    "        @test bdata == bases[b, :]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing process tomography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PastaQ\n",
    "using ITensors\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "\n",
    "\"\"\" HELPER FUNCTIONS \"\"\"\n",
    "function numgradslogZ(L::LPDO; accuracy=1e-8)\n",
    "  M = L.X\n",
    "  N = length(M)\n",
    "  grad_r = []\n",
    "  grad_i = []\n",
    "  for j in 1:N\n",
    "    push!(grad_r, zeros(ComplexF64, size(M[j])))\n",
    "    push!(grad_i, zeros(ComplexF64, size(M[j])))\n",
    "  end\n",
    "\n",
    "  epsilon = zeros(ComplexF64, size(M[1]))\n",
    "  # Site 1\n",
    "  for i in 1:length(epsilon)\n",
    "    epsilon[i] = accuracy\n",
    "    eps = ITensor(epsilon, inds(M[1]))\n",
    "    M[1] += eps\n",
    "    loss_p = 2.0 * lognorm(M)\n",
    "    M[1] -= eps\n",
    "    loss_m = 2.0 * lognorm(M)\n",
    "    grad_r[1][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "    epsilon[i] = im * accuracy\n",
    "    eps = ITensor(epsilon, inds(M[1]))\n",
    "    M[1] += eps\n",
    "    loss_p = 2.0 * lognorm(M)\n",
    "    M[1] -= eps\n",
    "    loss_m = 2.0 * lognorm(M)\n",
    "    grad_i[1][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "    epsilon[i] = 0.0\n",
    "  end\n",
    "\n",
    "  for j in 2:(N - 1)\n",
    "    epsilon = zeros(ComplexF64, size(M[j]))\n",
    "    for i in 1:length(epsilon)\n",
    "      epsilon[i] = accuracy\n",
    "      eps = ITensor(epsilon, inds(M[j]))\n",
    "      M[j] += eps\n",
    "      loss_p = 2.0 * lognorm(M)\n",
    "      M[j] -= eps\n",
    "      loss_m = 2.0 * lognorm(M)\n",
    "      grad_r[j][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "      epsilon[i] = im * accuracy\n",
    "      eps = ITensor(epsilon, inds(M[j]))\n",
    "      M[j] += eps\n",
    "      loss_p = 2.0 * lognorm(M)\n",
    "      M[j] -= eps\n",
    "      loss_m = 2.0 * lognorm(M)\n",
    "      grad_i[j][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "      epsilon[i] = 0.0\n",
    "    end\n",
    "  end\n",
    "  # Site N\n",
    "  epsilon = zeros(ComplexF64, size(M[N]))\n",
    "  for i in 1:length(epsilon)\n",
    "    epsilon[i] = accuracy\n",
    "    eps = ITensor(epsilon, inds(M[N]))\n",
    "    M[N] += eps\n",
    "    loss_p = 2.0 * lognorm(M)\n",
    "    M[N] -= eps\n",
    "    loss_m = 2.0 * lognorm(M)\n",
    "    grad_r[N][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "    epsilon[i] = im * accuracy\n",
    "    eps = ITensor(epsilon, inds(M[N]))\n",
    "    M[N] += eps\n",
    "    loss_p = 2.0 * lognorm(M)\n",
    "    M[N] -= eps\n",
    "    loss_m = 2.0 * lognorm(M)\n",
    "    grad_i[N][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "    epsilon[i] = 0.0\n",
    "  end\n",
    "\n",
    "  return grad_r - grad_i\n",
    "end\n",
    "\n",
    "#numgradslogZ(M::MPS; kwargs...) = numgradslogZ(LPDO(M); kwargs...)\n",
    "\n",
    "function numgradsnll(L::LPDO, data::Matrix{Pair{String,Pair{String,Int}}}, accuracy=1e-8)\n",
    "  M = L.X\n",
    "  N = length(M)\n",
    "  grad_r = []\n",
    "  grad_i = []\n",
    "  for j in 1:N\n",
    "    push!(grad_r, zeros(ComplexF64, size(M[j])))\n",
    "    push!(grad_i, zeros(ComplexF64, size(M[j])))\n",
    "  end\n",
    "\n",
    "  epsilon = zeros(ComplexF64, size(M[1]))\n",
    "  # Site 1\n",
    "  for i in 1:length(epsilon)\n",
    "    epsilon[i] = accuracy\n",
    "    eps = ITensor(epsilon, inds(M[1]))\n",
    "    M[1] += eps\n",
    "    loss_p = PastaQ.nll(L, data)\n",
    "    M[1] -= eps\n",
    "    loss_m = PastaQ.nll(L, data)\n",
    "    grad_r[1][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "    epsilon[i] = im * accuracy\n",
    "    eps = ITensor(epsilon, inds(M[1]))\n",
    "    M[1] += eps\n",
    "    loss_p = PastaQ.nll(L, data)\n",
    "    M[1] -= eps\n",
    "    loss_m = PastaQ.nll(L, data)\n",
    "    grad_i[1][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "    epsilon[i] = 0.0\n",
    "  end\n",
    "\n",
    "  for j in 2:(N - 1)\n",
    "    epsilon = zeros(ComplexF64, size(M[j]))\n",
    "    for i in 1:length(epsilon)\n",
    "      epsilon[i] = accuracy\n",
    "      eps = ITensor(epsilon, inds(M[j]))\n",
    "      M[j] += eps\n",
    "      loss_p = PastaQ.nll(L, data)\n",
    "      M[j] -= eps\n",
    "      loss_m = PastaQ.nll(L, data)\n",
    "      grad_r[j][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "      epsilon[i] = im * accuracy\n",
    "      eps = ITensor(epsilon, inds(M[j]))\n",
    "      M[j] += eps\n",
    "      loss_p = PastaQ.nll(L, data)\n",
    "      M[j] -= eps\n",
    "      loss_m = PastaQ.nll(L, data)\n",
    "      grad_i[j][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "      epsilon[i] = 0.0\n",
    "    end\n",
    "  end\n",
    "\n",
    "  # Site N\n",
    "  epsilon = zeros(ComplexF64, size(M[N]))\n",
    "  for i in 1:length(epsilon)\n",
    "    epsilon[i] = accuracy\n",
    "    eps = ITensor(epsilon, inds(M[N]))\n",
    "    M[N] += eps\n",
    "    loss_p = PastaQ.nll(L, data)\n",
    "    M[N] -= eps\n",
    "    loss_m = PastaQ.nll(L, data)\n",
    "    grad_r[N][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "    epsilon[i] = im * accuracy\n",
    "    eps = ITensor(epsilon, inds(M[N]))\n",
    "    M[N] += eps\n",
    "    loss_p = PastaQ.nll(L, data)\n",
    "    M[N] -= eps\n",
    "    loss_m = PastaQ.nll(L, data)\n",
    "    grad_i[N][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "    epsilon[i] = 0.0\n",
    "  end\n",
    "\n",
    "  return grad_r - grad_i\n",
    "end\n",
    "\n",
    "function numgradsTP(L::LPDO; accuracy=1e-8)\n",
    "  M = L.X\n",
    "  N = length(M)\n",
    "  grad_r = []\n",
    "  grad_i = []\n",
    "\n",
    "  for j in 1:N\n",
    "    push!(grad_r, zeros(ComplexF64, size(M[j])))\n",
    "    push!(grad_i, zeros(ComplexF64, size(M[j])))\n",
    "  end\n",
    "\n",
    "  epsilon = zeros(ComplexF64, size(M[1]))\n",
    "  # Site 1\n",
    "  for i in 1:length(epsilon)\n",
    "    epsilon[i] = accuracy\n",
    "    eps = ITensor(epsilon, inds(M[1]))\n",
    "    M[1] += eps\n",
    "    loss_p = PastaQ.TP(L)\n",
    "    M[1] -= eps\n",
    "    loss_m = PastaQ.TP(L)\n",
    "    grad_r[1][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "    epsilon[i] = im * accuracy\n",
    "    eps = ITensor(epsilon, inds(M[1]))\n",
    "    M[1] += eps\n",
    "    loss_p = PastaQ.TP(L)\n",
    "    M[1] -= eps\n",
    "    loss_m = PastaQ.TP(L)\n",
    "    grad_i[1][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "    epsilon[i] = 0.0\n",
    "  end\n",
    "\n",
    "  for j in 2:(N - 1)\n",
    "    epsilon = zeros(ComplexF64, size(M[j]))\n",
    "    for i in 1:length(epsilon)\n",
    "      epsilon[i] = accuracy\n",
    "      eps = ITensor(epsilon, inds(M[j]))\n",
    "      M[j] += eps\n",
    "      loss_p = PastaQ.TP(L)\n",
    "      M[j] -= eps\n",
    "      loss_m = PastaQ.TP(L)\n",
    "      grad_r[j][i] = (loss_p - loss_m) / (accuracy)\n",
    "\n",
    "      epsilon[i] = im * accuracy\n",
    "      eps = ITensor(epsilon, inds(M[j]))\n",
    "      M[j] += eps\n",
    "      loss_p = PastaQ.TP(L)\n",
    "      M[j] -= eps\n",
    "      loss_m = PastaQ.TP(L)\n",
    "      grad_i[j][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "      epsilon[i] = 0.0\n",
    "    endU\n",
    "  end\n",
    "\n",
    "  # Site N\n",
    "  epsilon = zeros(ComplexF64, size(M[N]))\n",
    "  for i in 1:length(epsilon)\n",
    "    epsilon[i] = accuracy\n",
    "    eps = ITensor(epsilon, inds(M[N]))\n",
    "    M[N] += eps\n",
    "    loss_p = PastaQ.TP(L)\n",
    "    M[N] -= eps\n",
    "    loss_m = PastaQ.TP(L)\n",
    "    grad_r[N][i] = (loss_p - loss_m) / (accuracy)\n",
    "    epsilon[i] = im * accuracy\n",
    "    eps = ITensor(epsilon, inds(M[N]))\n",
    "    M[N] += eps\n",
    "    loss_p = PastaQ.TP(L)\n",
    "    M[N] -= eps\n",
    "    loss_m = PastaQ.TP(L)\n",
    "    grad_i[N][i] = (loss_p - loss_m) / (im * accuracy)\n",
    "\n",
    "    epsilon[i] = 0.0\n",
    "  end\n",
    "\n",
    "  return grad_r - grad_i\n",
    "end\n",
    "\n",
    "@testset \"mpo-qpt: normalization\" begin\n",
    "  N = 5\n",
    "  χ = 4\n",
    "  U = randomprocess(N; χ=χ)\n",
    "  Λ = LPDO(PastaQ.unitary_mpo_to_choi_mps(U))\n",
    "  @test length(Λ) == N\n",
    "  logZ = 2 * lognorm(Λ.X)\n",
    "  sqrt_localZ = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localZ, localnorm=2)\n",
    "  @test logZ ≈ N * log(2) + 2.0 * sum(log.(sqrt_localZ))\n",
    "  @test abs2(norm(Λ.X)) ≈ 2^N\n",
    "end\n",
    "\n",
    "@testset \"mpo-qpt: grad logZ\" begin\n",
    "  N = 5\n",
    "  χ = 4\n",
    "\n",
    "  Random.seed!(1234)\n",
    "  U = randomprocess(N; χ=χ)\n",
    "  Λ = LPDO(PastaQ.unitary_mpo_to_choi_mps(U))\n",
    "  num_grad = numgradslogZ(Λ)\n",
    "\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "  @test norm(Λ.X)^2 ≈ 2^N\n",
    "  alg_grad, _ = PastaQ.gradlogZ(Λ; sqrt_localnorms=sqrt_localnorms)\n",
    "\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[1]), [1, 3, 2])\n",
    "  @test alg_gradient ≈ num_grad[1] rtol = 1e-3\n",
    "  for j in 2:(N - 1)\n",
    "    alg_gradient = permutedims(ITensors.array(alg_grad[j]), [2, 1, 3, 4])\n",
    "    @test alg_gradient ≈ num_grad[j] rtol = 1e-3\n",
    "  end\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[N]), [2, 1, 3])\n",
    "  @test alg_gradient ≈ num_grad[N] rtol = 1e-3\n",
    "end\n",
    "\n",
    "@testset \"mpo-qpt: grad nll\" begin\n",
    "  N = 4\n",
    "  χ = 2\n",
    "  nsamples = 10\n",
    "  Random.seed!(1234)\n",
    "  data_in = randompreparations(N, nsamples)\n",
    "  data_out = PastaQ.convertdatapoints(randompreparations(N, nsamples))\n",
    "  data = data_in .=> data_out\n",
    "\n",
    "  U = randomprocess(N; χ=χ)\n",
    "  Λ = LPDO(PastaQ.unitary_mpo_to_choi_mps(U))\n",
    "  num_grad = numgradsnll(Λ, data)\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "\n",
    "  alg_grad, _ = PastaQ.gradnll(Λ, data; sqrt_localnorms=sqrt_localnorms)\n",
    "  for j in 1:N\n",
    "    @test ITensors.array(alg_grad[j]) ≈ num_grad[j] rtol = 1e-3\n",
    "  end\n",
    "end\n",
    "\n",
    "@testset \"mpo-qpt: grad TP\" begin\n",
    "  N = 3\n",
    "  χ = 3\n",
    "  Random.seed!(1234)\n",
    "\n",
    "  Random.seed!(1234)\n",
    "  U = randomprocess(N; χ=χ)\n",
    "  Λ = LPDO(PastaQ.unitary_mpo_to_choi_mps(U))\n",
    "\n",
    "  num_grad = numgradsTP(Λ; accuracy=1e-8)\n",
    "  Γ_test = PastaQ.TP(Λ)\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "\n",
    "  alg_grad_logZ, logZ = PastaQ.gradlogZ(Λ; sqrt_localnorms=sqrt_localnorms)\n",
    "\n",
    "  alg_grad, Γ = PastaQ.gradTP(Λ, alg_grad_logZ, logZ; sqrt_localnorms=sqrt_localnorms)\n",
    "\n",
    "  @test Γ ≈ Γ_test\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[1]), [1, 3, 2])\n",
    "  @test alg_gradient ≈ num_grad[1] rtol = 1e-5\n",
    "  for j in 2:(N - 1)\n",
    "    alg_gradient = permutedims(ITensors.array(alg_grad[j]), [1, 3, 2, 4])\n",
    "    @test alg_gradient ≈ num_grad[j] rtol = 1e-5\n",
    "  end\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[N]), [1, 3, 2])\n",
    "  @test alg_gradient ≈ num_grad[N] rtol = 1e-5\n",
    "end\n",
    "\n",
    "@testset \"mpo-qpt: full gradients\" begin\n",
    "  N = 3\n",
    "  χ = 4\n",
    "  nsamples = 10\n",
    "  trace_preserving_regularizer = 0.1\n",
    "  Random.seed!(1234)\n",
    "  data_in = randompreparations(N, nsamples)\n",
    "  data_out = PastaQ.convertdatapoints(randompreparations(N, nsamples))\n",
    "  data = data_in .=> data_out\n",
    "\n",
    "  U = randomprocess(N; χ=χ)\n",
    "  Λ = LPDO(PastaQ.unitary_mpo_to_choi_mps(U))\n",
    "  TP_distance = PastaQ.TP(Λ)\n",
    "  logZ = log(tr(Λ))\n",
    "  NLL = PastaQ.nll(Λ, data)\n",
    "  num_gradZ = numgradslogZ(Λ)\n",
    "  num_gradNLL = numgradsnll(Λ, data)\n",
    "  num_gradTP = numgradsTP(Λ; accuracy=1e-5)\n",
    "\n",
    "  num_grads = num_gradZ + num_gradNLL + trace_preserving_regularizer * num_gradTP\n",
    "\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "\n",
    "  ex_loss = PastaQ.nll(Λ, data) + 2 * lognorm(Λ.X)\n",
    "  \n",
    "  display(Λ)\n",
    "  print(\" \")\n",
    "    \n",
    "  display(data)\n",
    "  alg_grads, loss = PastaQ.gradients(\n",
    "    Λ,\n",
    "    data;\n",
    "    sqrt_localnorms=sqrt_localnorms,\n",
    "    trace_preserving_regularizer=trace_preserving_regularizer,\n",
    "  )\n",
    "  @test ex_loss ≈ loss\n",
    "  for j in 1:N\n",
    "    @test ITensors.array(alg_grads[j]) ≈ num_grads[j] rtol = 1e-3\n",
    "  end\n",
    "end\n",
    "\n",
    "\"\"\" CHOI TESTS \"\"\"\n",
    "\n",
    "@testset \"lpdo-qpt: normalization\" begin\n",
    "  N = 10\n",
    "  χ = 4\n",
    "  ξ = 3\n",
    "  Λ = randomprocess(N; mixed=true, ξ=ξ, χ=χ)\n",
    "\n",
    "  @test length(Λ) == N\n",
    "  logZ = logtr(Λ)\n",
    "  localZ = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=localZ, localnorm=2)\n",
    "  @test logZ ≈ N * log(2) + 2.0 * sum(log.(localZ))\n",
    "  @test tr(Λ) ≈ 2^N\n",
    "end\n",
    "\n",
    "@testset \"lpdo-qst: grad logZ\" begin\n",
    "  N = 5\n",
    "  χ = 4\n",
    "  ξ = 3\n",
    "\n",
    "  Λ = randomprocess(N; mixed=true, χ=χ, ξ=ξ)\n",
    "  num_grad = numgradslogZ(Λ)\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "  @test tr(Λ) ≈ 2^N\n",
    "  alg_grad, _ = PastaQ.gradlogZ(Λ; sqrt_localnorms=sqrt_localnorms)\n",
    "\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[1]), [1, 2, 4, 3])\n",
    "  for j in 2:(N - 1)\n",
    "    alg_gradient = permutedims(ITensors.array(alg_grad[j]), [2, 3, 1, 4, 5])\n",
    "    @test alg_gradient ≈ num_grad[j] rtol = 1e-3\n",
    "  end\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[N]), [2, 3, 1, 4])\n",
    "  @test alg_gradient ≈ num_grad[N] rtol = 1e-3\n",
    "end\n",
    "\n",
    "@testset \"lpdo-qst: grad nll\" begin\n",
    "  N = 5\n",
    "  χ = 4\n",
    "  ξ = 3\n",
    "\n",
    "  nsamples = 10\n",
    "  Random.seed!(1234)\n",
    "  data_in = randompreparations(N, nsamples)\n",
    "  data_out = PastaQ.convertdatapoints(randompreparations(N, nsamples))\n",
    "  data = data_in .=> data_out\n",
    "\n",
    "  Λ = randomprocess(N; mixed=true, χ=χ, ξ=ξ)\n",
    "  num_grad = numgradsnll(Λ, data)\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "  alg_grad, loss = PastaQ.gradnll(Λ, data; sqrt_localnorms=sqrt_localnorms)\n",
    "  @test loss ≈ PastaQ.nll(Λ, data)\n",
    "\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[1]), [3, 4, 1, 2])\n",
    "  @test alg_gradient ≈ num_grad[1] rtol = 1e-3\n",
    "  for j in 2:(N - 1)\n",
    "    alg_gradient = permutedims(ITensors.array(alg_grad[j]), [4, 5, 2, 3, 1])\n",
    "    @test alg_gradient ≈ num_grad[j] rtol = 1e-3\n",
    "  end\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[N]), [3, 4, 1, 2])\n",
    "  @test alg_gradient ≈ num_grad[N] rtol = 1e-3\n",
    "end\n",
    "\n",
    "@testset \"lpdo-qpt: grad TP\" begin\n",
    "  N = 3\n",
    "  χ = 4\n",
    "  ξ = 3\n",
    "  Λ = randomprocess(N; mixed=true, χ=χ, ξ=ξ)\n",
    "\n",
    "  num_grad = numgradsTP(Λ; accuracy=1e-8)\n",
    "  Γ_test = PastaQ.TP(Λ)\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "  Γ_test = PastaQ.TP(Λ)\n",
    "\n",
    "  alg_grad_logZ, logZ = PastaQ.gradlogZ(Λ; sqrt_localnorms=sqrt_localnorms)\n",
    "\n",
    "  alg_grad, Γ = PastaQ.gradTP(Λ, alg_grad_logZ, logZ; sqrt_localnorms=sqrt_localnorms)\n",
    "\n",
    "  @test Γ ≈ Γ_test\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[1]), [3, 1, 4, 2])\n",
    "  @test alg_gradient ≈ num_grad[1] rtol = 1e-3\n",
    "  for j in 2:(N - 1)\n",
    "    alg_gradient = permutedims(ITensors.array(alg_grad[j]), [3, 1, 4, 2, 5])\n",
    "    @test alg_gradient ≈ num_grad[j] rtol = 1e-3\n",
    "  end\n",
    "  alg_gradient = permutedims(ITensors.array(alg_grad[N]), [3, 1, 4, 2])\n",
    "  @test alg_gradient ≈ num_grad[N] rtol = 1e-3\n",
    "end\n",
    "\n",
    "@testset \"lpdo-qpt: full gradients\" begin\n",
    "  N = 3\n",
    "  χ = 3\n",
    "  ξ = 2\n",
    "\n",
    "  trace_preserving_regularizer = 0.1\n",
    "  nsamples = 10\n",
    "  Random.seed!(1234)\n",
    "  data_in = randompreparations(N, nsamples)\n",
    "  data_out = PastaQ.convertdatapoints(randompreparations(N, nsamples))\n",
    "  data = data_in .=> data_out\n",
    "\n",
    "  Λ = randomprocess(N; mixed=true, χ=χ, ξ=ξ)\n",
    "  num_grad = numgradsnll(Λ, data)\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "  alg_grad, loss = PastaQ.gradnll(Λ, data; sqrt_localnorms=sqrt_localnorms)\n",
    "\n",
    "  TP_distance = PastaQ.TP(Λ)\n",
    "  logZ = log(tr(Λ))\n",
    "  NLL = PastaQ.nll(Λ, data)\n",
    "  num_gradZ = numgradslogZ(Λ)\n",
    "  num_gradNLL = numgradsnll(Λ, data)\n",
    "  num_gradTP = numgradsTP(Λ; accuracy=1e-5)\n",
    "\n",
    "  num_grads = num_gradZ + num_gradNLL + trace_preserving_regularizer * num_gradTP\n",
    "\n",
    "  sqrt_localnorms = []\n",
    "  PastaQ.normalize!(Λ; (sqrt_localnorms!)=sqrt_localnorms, localnorm=2)\n",
    "\n",
    "  ex_loss = PastaQ.nll(Λ, data) + 2 * lognorm(Λ.X)\n",
    "  alg_grads, loss = PastaQ.gradients(\n",
    "    Λ,\n",
    "    data;\n",
    "    sqrt_localnorms=sqrt_localnorms,\n",
    "    trace_preserving_regularizer=trace_preserving_regularizer,\n",
    "  )\n",
    "  @test ex_loss ≈ loss\n",
    "  for j in 1:N\n",
    "    @test ITensors.array(alg_grads[j]) ≈ num_grads[j] rtol = 1e-3\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PastaQ\n",
    "using Random\n",
    "using ITensors\n",
    "using Observers\n",
    "using Optimisers: Optimisers\n",
    "\n",
    "Random.seed!(1234)\n",
    "\n",
    "# 1. Quantum process tomography of a unitary circuit\n",
    "\n",
    "# Make the random circuit\n",
    "N = 3\n",
    "depth = 4\n",
    "nshots = 100\n",
    "circuit = randomcircuit(N,depth=depth)\n",
    "ρ = runcircuit(circuit)\n",
    "\n",
    "#print(circuit)\n",
    "# Generate samples\n",
    "#print(bases)\n",
    "#data,Û= getsamples(ρ, bases,nshots)\n",
    "data = getsamples(ρ, nshots)\n",
    "\n",
    "\n",
    "#writesamples(data, U, \"data/qpt_circuit.h5\")\n",
    "\n",
    "# Load target state and measurements. Each samples is built out\n",
    "# of an input state (`first.(data)`) to the quantum channel, and the\n",
    "# measurement output (`last.(data)`) after a local basis rotation.\n",
    "#data, Û = readsamples(\"data/qpt_circuit.h5\")\n",
    "\n",
    "# Split data into a train and test dataset\n",
    "train_data, test_data = split_dataset(data; train_ratio=0.9)\n",
    "\n",
    "display(train_data)\n",
    "\n",
    "# Set parameters\n",
    "N = length(Û)     # Number of qubits\n",
    "χ = maxlinkdim(Û) # Bond dimension of variational MPS\n",
    "\n",
    "# Initialize the unitary MPO\n",
    "U0 = randomprocess(Û; χ=χ)\n",
    "\n",
    "opt = Optimisers.Descent(0.01)\n",
    "\n",
    "F(U::MPO; kwargs...) = fidelity(U, Û; process=true)\n",
    "obs = Observer([\"F\" => F])\n",
    "\n",
    "# Initialize stochastic gradient descent optimizer\n",
    "@show maxlinkdim(U0)\n",
    "\n",
    "# Run process tomography\n",
    "println(\"Run process tomography to learn noiseless circuit U\")\n",
    "U = tomography(\n",
    "  train_data,\n",
    "  U0;\n",
    "  test_data=test_data,\n",
    "  optimizer=opt,\n",
    "  batchsize=500,\n",
    "  epochs=5,\n",
    "  (observer!)=obs,\n",
    "  print_metrics=[\"F\"],\n",
    ")\n",
    "\n",
    "@show maxlinkdim(U)\n",
    "println()\n",
    "\n",
    "# Noisy circuit\n",
    "# Generate samples\n",
    "data, Λ = getsamples(\n",
    "  circuit,\n",
    "  nshots;\n",
    "  local_basis=[\"X\", \"Y\", \"Z\"],\n",
    "  process=true,\n",
    "  noise=(\"amplitude_damping\", (γ=0.01,)),\n",
    ")\n",
    "writesamples(data, Λ, \"data/qpt_circuit_noisy.h5\")\n",
    "\n",
    "# Load data and target Choi matrix\n",
    "data, Φ = readsamples(\"data/qpt_circuit_noisy.h5\")\n",
    "\n",
    "# Split data into a train and test dataset\n",
    "train_data, test_data = split_dataset(data; train_ratio=0.9)\n",
    "\n",
    "# Set up\n",
    "N = length(Φ)\n",
    "χ = 8\n",
    "ξ = 2\n",
    "\n",
    "# Initialize the Choi LPDO\n",
    "Λ0 = randomprocess(Φ; mixed=true, χ=χ, ξ=ξ)\n",
    "\n",
    "# Initialize stochastic gradient descent optimizer\n",
    "opt = Optimisers.ADAM()\n",
    "\n",
    "F(Λ::LPDO; kwargs...) = fidelity(Λ, Φ; process=true)\n",
    "obs = Observer([\"F\" => F])\n",
    "\n",
    "# Run process tomography\n",
    "println(\"Run process tomography to learn noisy process Λ\")\n",
    "@disable_warn_order begin\n",
    "  Λ = tomography(\n",
    "    train_data,\n",
    "    Λ0;\n",
    "    test_data=test_data,\n",
    "    optimizer=opt,\n",
    "    batchsize=500,\n",
    "    epochs=5,\n",
    "    (observer!)=obs,\n",
    "    print_metrics=[\"F\"],\n",
    "  )\n",
    "end\n",
    "@show maxlinkdim(Λ.X)\n",
    "println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
